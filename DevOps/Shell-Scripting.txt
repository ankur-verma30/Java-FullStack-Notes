ğŸ”· Linux Commands
1ï¸âƒ£ free â€” Check RAM (Memory) Usage
Displays information about system memory â€” total, used, and free RAM & swap.

ğŸ”„ Syntax:
ğŸ”— free
ğŸ”— free -m   # Show in MB
ğŸ”— free -g   # Show in GB

âœ… Example:
ğŸ”— free -g

âœ… Output Example:
              total        used        free      shared  buff/cache   available
Mem:              8           2           3           0           2           5
Swap:             2           0           2

ğŸ‘‰ Meaning:
âœ”ï¸ total â†’ Total RAM in the system
âœ”ï¸ used â†’ RAM currently used
âœ”ï¸ free â†’ RAM available
âœ”ï¸ buff/cache â†’ Memory used by kernel buffers & cache
âœ”ï¸ available â†’ Memory available for new processes

âš¡Use in scripts:
To check if a server has enough memory before deploying or running a heavy service.

2ï¸âƒ£ nproc â€” Get Number of CPU Cores
Displays the number of CPU cores available for processing.

âœ… Syntax: nproc
âœ… Example Output: 4

ğŸ‘‰ The system has 4 CPU cores (useful for tuning multi-threaded tasks or Docker containers).

ğŸ‘‰ Use in scripts:
Automatically detect CPU cores to parallelize builds or workloads.
âœ… Example: make -j$(nproc)
â†’ Compiles code using all available CPU cores.


3ï¸âƒ£ df -h â€” Check Disk Usage
Shows disk space usage on all mounted file systems.

âœ… Syntax: df -h

âœ… Example Output:
Filesystem      Size  Used Avail Use% Mounted on
/dev/xvda1       30G   10G   18G  36% /
tmpfs           1.9G     0  1.9G   0% /dev/shm

âœ”ï¸ Filesystem â†’ Name of the disk/partition
âœ”ï¸ Size â†’ Total disk size
âœ”ï¸ Used â†’ Space already used
âœ”ï¸ Avail â†’ Free space available
âœ”ï¸ Use% â†’ Percentage of disk used
âœ”ï¸ Mounted on â†’ Directory where the disk is attached

ğŸ‘‰ Check if thereâ€™s enough disk space before uploading files, running backups, or installing packages.

ğŸ”· top Command â€” Real-Time Process & Resource Monitor

ğŸ”„ Purpose:
Shows real-time information about:
1ï¸âƒ£ Running processes
2ï¸âƒ£ CPU & memory usage
3ï¸âƒ£ System load
4ï¸âƒ£ Uptime
5ï¸âƒ£ Process IDs (PIDs)
6ï¸âƒ£ Users running those processes
ğŸ‘‰ Itâ€™s like Task Manager in Windows â€” but for Linux CLI.

ğŸ‘‰ Syntax : top

ğŸ‘‰ can also use:
ğŸ”— top -u <username>     # Show processes of a specific user
ğŸ”— top -p <pid>          # Monitor a specific process ID
ğŸ”— top -n 1              # Show output only once and exit


âœ… Sample Output:
top - 10:12:36 up 3 days,  2:04,  1 user,  load average: 0.07, 0.03, 0.01
Tasks: 120 total,   1 running, 119 sleeping,   0 stopped,   0 zombie
%Cpu(s):  2.3 us,  1.2 sy,  0.0 ni, 96.2 id,  0.2 wa,  0.0 hi,  0.1 si,  0.0 st
MiB Mem :   7982.4 total,   2345.1 free,   1223.5 used,   4413.8 buff/cache
MiB Swap:   2048.0 total,   2048.0 free,      0.0 used.   6037.3 avail Mem 

PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
1234 ec2-user  20   0  123456  5678  1234 S   1.3  0.2   0:02.34 java
5678 root      20   0  87654  4321  3210 S   0.7  0.1   0:01.45 sshd


ğŸ”„ Output Breakdown:
| Field                | Description                                          |
| -------------------- | ---------------------------------------------------- |
| **PID**              | Process ID                                           |
| **USER**             | Owner of the process                                 |
| **PR / NI**          | Process priority & nice value                        |
| **VIRT / RES / SHR** | Virtual, Resident & Shared memory usage              |
| **S**                | Process status (`R` = running, `S` = sleeping, etc.) |
| **%CPU / %MEM**      | CPU and memory usage of the process                  |
| **TIME+**            | Total CPU time used                                  |
| **COMMAND**          | Command/program name                                 |


ğŸ”„ Top Section Details: 
1ï¸âƒ£ Uptime & Load Average
load average: 0.07, 0.03, 0.01
â¤ Indicates system load in the last 1, 5, and 15 minutes.
(Lower is better; if load > number of CPUs, system is overloaded.)

2ï¸âƒ£ Tasks
Tasks: 120 total, 1 running, 119 sleeping
â¤ Shows how many processes are running, sleeping, or stopped.

3ï¸âƒ£ CPU Usage
%Cpu(s): 2.3 us, 1.2 sy, 96.2 id
âœ”ï¸ us = user processes
âœ”ï¸ sy = system processes
âœ”ï¸ id = idle time
âœ”ï¸ wa = waiting for I/O

4ï¸âƒ£ Memory Usage
Mem: 7982 total, 1223 used, 4413 buff/cache
â¤ Monitors RAM and swap usage in real-time.

ğŸ”„ Top Command Shortcuts
| Key           | Function                                 |
| ------------- | ---------------------------------------- |
| **q**         | Quit `top`                               |
| **k**         | Kill a process (youâ€™ll be asked for PID) |
| **r**         | Renice (change process priority)         |
| **M**         | Sort by memory usage                     |
| **P**         | Sort by CPU usage                        |
| **1**         | Show CPU usage for each core             |
| **u**         | Filter processes by user                 |
| **Shift + E** | Change memory units (KB â†’ MB â†’ GB)       |


ğŸ”„ In Shell Scripts
You usually donâ€™t use top directly in scripts (since itâ€™s interactive),
but you can use:
ğŸ”— top -b -n 1

ğŸ‘‰ This runs top in batch mode (non-interactive) â†’ useful for automation or logging.

âœ… Example:
ğŸ”— top -b -n 1 | head -15 > system_report.txt
â†’ Saves top 15 lines of top output into a file.

ğŸ”· Shell Scripting
A shell script is a file containing a series of Linux commands that the shell (command-line interpreter) executes one after another automatically.

Think of it like:
ğŸ§© Instead of typing each command manually in the terminal, you write them in a file and let the system run them all at once.

ğŸ”· Why Use Shell Scripting?
â¤ Automation
â¤ Reusability
â¤ Security

Creating a Shell Script
ğŸ”— nano script.sh --> file should be of .sh extension 


ğŸ”„ Shebang (#! ) in Shell Scripting
A shebang (#!) is the first line in a shell script that tells the system which interpreter should be used to execute the script.

âœ… Syntax:
ğŸ”— #!/bin/

 âœ…Example 1 â€” Bash Script
#!/bin/bash
echo "Hello, World!"
â¡ï¸ This tells Linux:
"Use the bash shell (located at /bin/bash) to run this script."

ğŸ”„ Why Shebang is Important
â¤ Specifies interpreter explicitly â€” ensures script runs the same way everywhere.
â¤ Avoids confusion â€” even if a userâ€™s default shell is different (like zsh or fish).

âš¡ Used by system to know how to execute when you run:
./script.sh
âš¡ save the file in vim editor and exit by :wq

Running a Shell Script
1ï¸âƒ£ Can use sh prefix to run a script.
ğŸ”— sh script.sh

2ï¸âƒ£ Or make it executable and run directly:
ğŸ”— chmod +x script.sh   # Make it executable


ğŸ”„ Always write metadata information about the script before writing the script
##########################
# Author: Ankur
# Date: 12/11/2025
#
# This scripts outputs the node health
#
# Version:v1
#####################################


ğŸ”· Writing shell script to check the health of the VM Machines
ğŸ”„ Method 1: Using echo command to write the readabe scripts 
#!/bin/bash


echo "Print the disk space"
ğŸ”— df -h

echo "Print the memory"
ğŸ”— free -g


echo "Print the number of CPU"
ğŸ”— nproc
â¤ However for large and complex scripts writing echo is not a good idea and its a very cumbersome task

ğŸ”„ Method 2: use Debug mode to write the script

#!/bin/bash
ğŸ”— set -x   # Enable debug mode
ğŸ”— df -h
ğŸ”— free -g
ğŸ”— nproc

â¤ The set -x command enables debug mode, which prints each command and its arguments to the terminal as they are executed.
â¤ This makes it easier to write and troubleshoot the script since you can see exactly what commands are being run.


ğŸ”· ps -ef Command- Process status
ps -ef shows a complete list of all running processes on a Linux system in full detail.
It is one of the most common commands used in DevOps, EC2, Docker, Kubernetes, troubleshooting

Breakdown of Operations
ps â†’ Process Status
-e â†’ Show all processes
-f â†’ Show full-format listing (detailed)

ğŸ”· Difference between ps and top
| Command    | Purpose                                           |
| ---------- | ------------------------------------------------- |
| **ps -ef** | Shows a one-time snapshot of all processes        |
| **top**    | Shows real-time updates of CPU, memory, processes |

1ï¸âƒ£ Check if a process is running
ğŸ”— ps -ef | grep nginx

2ï¸âƒ£ Find a process by port (with netstat/lsof)
ğŸ”— sudo lsof -i :8080

3ï¸âƒ£ then kill it:
ğŸ”— kill -9 <PID>

4ï¸âƒ£ Find parent-child process relationships
ğŸ”— ps -ef --forest
 
5ï¸âƒ£ Kill a specific running process
ğŸ”— kill -9 <PID>

5ï¸âƒ£ Check JVM, MySQL, Python processes
ğŸ”— ps -ef | grep java
ğŸ”— ps -ef | grep python

ğŸ”„ Working of awk command
awk is a powerful text-processing tool used to:
    âœ”ï¸ Search text
    âœ”ï¸ Filter data
    âœ”ï¸ Extract columns
    âœ”ï¸ Perform calculations
    âœ”ï¸ Format output
    âœ”ï¸ Process logs
It works line by line and splits each line into fields (columns).

ğŸ”„ Basic Syntax
awk 'pattern { action }' filename

â¤ pattern â†’ what to search for
â¤ action â†’ what to do when pattern matches
â¤ $1, $2, $3... â†’ columns
â¤ $0 â†’ whole line

âœ”ï¸ $1 â†’ first column
âœ”ï¸ $2 â†’ second column
âœ”ï¸ $0 â†’ entire line
âœ”ï¸ NF â†’ number of fields
âœ”ï¸ NR â†’ line number

âœ… Example:
ps -ef | grep amazon | awk -F" " '{print $2}' 


ğŸ”· set commands
| Option        | Meaning                            |
| ------------- | ---------------------------------- |
| `-e`          | Exit on any error                  |
| `-u`          | Exit on using undefined variables  |
| `-o pipefail` | Fail pipeline if any command fails |

âœ…Example:
set -euo pipefail  # in almost all professional scripts this is used


ğŸ”· curl command
curl (Client URL) is a command-line tool used to send HTTP requests and interact with APIs, servers, URLs.

Supports many protocols: HTTP, HTTPS, FTP, SCP, SFTP, SMTP, etc.

Very commonly used in DevOps, automation, shell scripting, backend testing, CI/CD pipelines.

ğŸ”„ Basic curl Commands (Most Used)
1ï¸âƒ£ GET request (default)
ğŸ”— curl https://api.example.com/users

2ï¸âƒ£ Save output to a file
ğŸ”— curl -o output.json https://api.example.com/users

3ï¸âƒ£ Follow redirects
ğŸ”— curl -L https://example.com

4ï¸âƒ£ Show only HTTP response code
ğŸ”— curl -o /dev/null -w "%{http_code}\n" -s https://example.com

5ï¸âƒ£ Send a POST request with JSON body
ğŸ”— curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"name":"Ankur", "role":"DevOps"}' \
  https://api.example.com/create

ğŸ”„ Headers in curl
Add a custom header
ğŸ”— curl -H "Authorization: Bearer <token>" https://api.example.com/data

ğŸ”„ Download a file
ğŸ”— curl -O https://example.com/file.zip

ğŸ”„ Upload a file
ğŸ”— curl -F "file=@/path/to/file.txt" https://api.example.com/upload

ğŸ”„ Verbose Mode (Debugging APIs)
ğŸ”— curl -v https://example.com
ğŸ‘‰ Shows:
â¤ request headers
â¤ response headers
â¤ SSL details

ğŸ”„ Check only response headers
ğŸ”— curl -I https://example.com

ğŸ”„ Send form data (like HTML form)
ğŸ”— curl -X POST -F "username=ankur" -F "password=1234" https://example.com/login

ğŸ”„ Use curl with authentication
Basic Auth
ğŸ”— curl -u user:password https://example.com

ğŸ”„ Send multiple headers
ğŸ”— curl -H "Accept: application/json" \
     -H "X-API-KEY: 12345" \
     https://example.com

ğŸ”„ Test API speed
ğŸ”— curl -w "@curl-format.txt" -o /dev/null -s https://example.com

ğŸ”„ wget Command
ğŸ”— wget dummylog.log 
â¤ It downloads the log file into your local machine.

ğŸ”„ find command
â¤ find is used to search files and directories in a directory hierarchy.
â¤ You can search by name, type, size, extension, time, permissions, owner, etc.
â¤ Supports powerful actions: delete, move, exec 


ğŸ”· If else and for loop in Shell scripting
1ï¸âƒ£ IF Statement
ğŸ‘‰ Syntax
if [ condition ]; then
    commands
fi

âœ… Example
num=10
if [ $num -gt 5 ]; then
    echo "Number is greater than 5"
fi

2ï¸âƒ£ IFâ€“ELSE Statement
ğŸ‘‰ Syntax
if [ condition ]; then
    commands
else
    commands
fi

âœ… Example
n=3
if [ $n -eq 3 ]; then
    echo "Matched"
else
    echo "Not matched"
fi

3ï¸âƒ£ IFâ€“ELIFâ€“ELSE Ladder (else-if)
ğŸ‘‰ Syntax
if [ condition1 ]; then
    commands
elif [ condition2 ]; then
    commands
else
    commands
fi

âœ… Example
marks=90

if [ $marks -ge 90 ]; then
    echo "Grade A"
elif [ $marks -ge 80 ]; then
    echo "Grade B"
else
    echo "Grade C"
fi

ğŸ”„ Common Conditions in Shell
âš¡ Numeric:
-eq   # equal
-ne   # not equal
-gt   # greater than
-lt   # less than
-ge   # greater or equal
-le   # less or equal

âš¡ Strings:
=     # equal
!=    # not equal
-z    # empty string
-n    # non-empty string

âš¡ Files:
-e file   # exists
-f file   # regular file
-d dir    # directory
-r        # readable
-w        # writable
-x        # executable

âœ… FOR Loop in Shell Scripting
1ï¸âƒ£ Basic FOR Loop
for i in 1 2 3 4 5
do
    echo "Number: $i"
done

2ï¸âƒ£ FOR Loop with Range
for i in {1..10}
do
    echo $i
done

3ï¸âƒ£ FOR Loop with Step Size
for i in {1..10..2}
do
    echo $i
done

4ï¸âƒ£ FOR Loop Through Files
for file in *.sh
do
    echo "File: $file"
done

5ï¸âƒ£ FOR Loop in Classic C-Style (Most used in DevOps)
for ((i=1; i<=5; i++))
do
    echo "Iteration: $i"
done

ğŸ”„ IF inside a FOR Loop 
for file in *.log
do
    if [ -s $file ]; then
        echo "$file is not empty"
    else
        echo "$file is empty"
    fi
done


ğŸ”· trap command
trap is used to catch and handle signals in a shell script.
It allows you to run a custom command before the script exits, when it receives an interrupt, or when an error occurs.

ğŸ”„ Important signals 
| Signal    | Number | Meaning                                |
| --------- | ------ | -------------------------------------- |
| `SIGINT`  | 2      | Ctrl + C interrupt                     |
| `SIGTERM` | 15     | Termination request                    |
| `EXIT`    | 0      | Script exiting                         |
| `ERR`     | â€”      | When any command fails (with `set -e`) |

âœ…Example:
trap "echo 'You pressed Ctrl+C. Stopping script...'" SIGINT

âœ… Example: Write the script to count the number of s in the letter mississipi
1ï¸âƒ£ Method 1: using for loop and if condition
#!/bin/bash
count=0
for letter in mississipi
do
    if [ "$letter" == "s" ]; then
        count=$((count+1))
    fi
done
echo "Number of s's: $count"

2ï¸âƒ£ Using grep + wc -l
#!/bin/bash
count=$(echo "mississipi" | grep -o "s" | wc -l)
echo "Number of s's: $count"

1ï¸âƒ£ echo "mississipi"
â¤ Prints the string mississipi to standard output.

2ï¸âƒ£ | grep -o "s"
â¤ grep -o prints each matching "s" on a new line.
âœ… Output becomes:
s
s
s
s
(4 lines because "s" occurs 4 times)

3ï¸âƒ£ | wc -l
â¤ wc -l counts the number of lines.
â¤ Here, each "s" is one line â†’ 4.

5ï¸âƒ£ count=$( ... )
â¤ Stores the output (number 4) into the count variable.

6ï¸âƒ£ echo "Number of s's: $count"
â¤ Prints the final count.

3ï¸âƒ£ Using â€œ<<<â€ Here-String Operator
#!/bin/bash
x="mississipi"

grep -o "s" <<< "$x" | wc -l

â“ What is <<< ?
â¤ <<< is called a here-string.
â¤ It sends the content of a variable as input to a command.

Equivalent to:
echo "$x" | command

1ï¸âƒ£ x="mississipi"
â¤ Stores the string in variable x.

2ï¸âƒ£ grep -o "s" <<< "$x"
â¤ Takes the string directly from the variable and passes it to grep.
â¤ Again, grep -o prints each "s" on a separate line.

3ï¸âƒ£ | wc -l
â¤ Counts the number of lines â†’ number of occurrences of s.

Thus output is 4.

ğŸ”„ Difference between Method 2 and Method 3
| Method            | How Input is Passed | When to Use             |                            |
| ----------------- | ------------------- | ----------------------- | -------------------------- |
| **echo "text"     | grep**              | Through a pipeline      | Good for hardcoded strings |
| **grep <<< "$x"** | Via here-string     | Best for variable input |                            |


ğŸ”· Crontab
ğŸ“Œ Crontab = Cron Table
â¤ It is a file that contains scheduled commands.
â¤ These commands run automatically at specific times/dates.
â¤ Cron is the time-based job scheduler in Linux.

ğŸ”„ Why is Crontab used?
To automate tasks such as:
âœ”ï¸ Backup files
âœ”ï¸ Clean logs
âœ”ï¸ Start/stop services
âœ”ï¸ Run scripts at fixed intervals
âœ”ï¸ Send reports or emails
âœ”ï¸ Trigger monitoring or health checks
âœ”ï¸ Rotate logs
âœ”ï¸ Automate deployments (rare but possible)

â“ Where is it used in DevOps?
âœ”ï¸ CI/CD automation
âœ”ï¸ Data pipeline scheduling
âœ”ï¸ Server maintenance
âœ”ï¸ EC2 instance tasks
âœ”ï¸ Kubernetes node scripts
âœ”ï¸ Managing cron jobs in Docker containers
âœ”ï¸ Log cleanup on servers

ğŸ”„ Crontab Syntax
A cron job has 5 time fields + command:
*  *  *  *  *    command
â”‚  â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€ Day of week (0â€“6)  Sun=0
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€ Month (1â€“12)
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€ Day of month (1â€“31)
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hour (0â€“23)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Minute (0â€“59)

ğŸ”„ Basic Crontab Commands
ğŸ‘‰ Edit cron jobs:
ğŸ”— crontab -e

ğŸ‘‰ View cron jobs:
ğŸ”— crontab -l

ğŸ‘‰ Delete all jobs:
ğŸ”— crontab -r

ğŸ”„ How to open a read-only file?
ğŸ”— vim -r test.txt

ğŸ”· Difference between soft link and hard-link?
1ï¸âƒ£ Soft Link (Symbolic Link)
â¤ Works like a shortcut or pointer to another file.
â¤ Stores the path of the original file.
â¤ If original file is deleted â†’ soft link breaks (becomes unusable).
â¤ Can link directories.
â¤ Can link across different file systems (partitions/disks).
â¤ Has a different inode number from the original.
â¤ Size is small (stores only file path).

ğŸ”„ Create soft link:
ğŸ”— ln -s original.txt softlink.txt


2ï¸âƒ£ Hard Link
â¤ A duplicate directory entry pointing to the same underlying file.
â¤ Both original and hard link share the same inode number.
â¤ If original file is deleted â†’ hard link still works
(because data still exists).
â¤ Cannot link directories.
â¤ Cannot link across different file systems.
â¤ Acts like a copy, but does not take extra space (until content changes).
â¤ Content is the same for both.

ğŸ”„ Create hard link:
ğŸ”— ln original.txt hardlink.txt

ğŸ†š Comparison between soft link and hard-link?
| Feature                     | Soft Link (Symbolic) | Hard Link                   |
| --------------------------- | -------------------- | --------------------------- |
| Link Type                   | Shortcut             | Actual mirror pointer       |
| Inode Number                | Different            | Same inode as original      |
| Breaks if original deleted? | âŒ Yes                | âœ” No                        |
| Can link directories?       | âœ” Yes                | âŒ No                        |
| Can cross file systems?     | âœ” Yes                | âŒ No                        |
| File size                   | Small (path only)    | Same as file (shares inode) |
| Acts like                   | Shortcut             | Real file clone             |


ğŸ”· Disadvantages of Shell Scripting
1ï¸âƒ£ Hard to Debug
â¤ Error messages are not always clear.
â¤ Debugging large shell scripts is difficult.

2ï¸âƒ£ Not Portable Across Shells
â¤ Bash script may not run the same in sh, zsh, or dash.
â¤ Different OS versions behave differently.

3ï¸âƒ£ Poor Error Handling
â¤ No strong exception-handling mechanism.
â¤ Small mistakes can break the entire script.

4ï¸âƒ£ Difficult to Maintain Large Scripts
â¤ Not suitable for large, complex programs.
â¤ Code becomes messy without strict structure.

5ï¸âƒ£ Security Risks
â¤ Easy to accidentally expose secrets (passwords, keys).
â¤ Unsafe use of eval, input parameters, or file paths can cause vulnerabilities.

6ï¸âƒ£ Performance Limitations
â¤ Slower than compiled languages (C, Go, Java).
â¤ Not good for CPU-heavy tasks.

7ï¸âƒ£ Weak Typing
â¤ No strong data types â†’ errors occur silently.
â¤ Strings and numbers mix easily without warnings.

8ï¸âƒ£ Limited Functionality
â¤ Cannot create advanced applications (APIs, microservices).
â¤ Mostly useful only for automation, file operations, and system tasks.

9ï¸âƒ£ Error-Prone Syntax
â¤ Brackets must be spaced correctly: [ $a -eq $b ]
â¤ Quotes, spaces, tabs â†’ small mistakes break script.

ğŸ”Ÿ No Standard Library
â¤ Must use external tools (grep, awk, sed) for many operations.


1ï¸âƒ£ Traceroute Command 
â¤ traceroute shows the path (hops) your packet takes from your machine to a destination (server/website).
â¤ Each "hop" is a router or network device.
â¤ Used to diagnose network issues like high latency, packet loss, or routing loops.

âœ… How it works
â¤ Sends packets with increasing TTL (Time-To-Live).
â¤ Each router along the path reduces the TTL.
â¤ When TTL becomes zero, the router returns an ICMP Time Exceeded message.
â¤ Traceroute uses these messages to map the entire route.

ğŸ§ª Example
traceroute google.com
Output shows:
    âœ”ï¸ Hop number
    âœ”ï¸ Router IP
    âœ”ï¸ Time taken in ms (latency)

ğŸ¯ Why DevOps uses traceroute
â¤ Checking connectivity between EC2 â†’ RDS, local â†’ server.
â¤ Diagnosing slow network issues.
â¤ Troubleshooting VPC networking problems.
â¤ Identifying firewall or routing issues.

2ï¸âƒ£ Logrotate â€” DevOps Notes
A Linux utility that automatically manages log files by:
    âœ”ï¸ Rotating (renaming old logs)
    âœ”ï¸ Compressing (gzip)
    âœ”ï¸ Deleting old logs
    âœ”ï¸ Setting retention policies
    âœ”ï¸ Scheduling (daily/weekly/monthly)
    âœ”ï¸ Ensuring logs don't fill the disk

ğŸ”„ ğŸ›  Why DevOps Needs Logrotate
Because logs can grow very large and crash servers by consuming disk space.

You use logrotate to:
    âœ”ï¸ Prevent /var/log/ from filling
    âœ”ï¸ Maintain system logs
    âœ”ï¸ Manage application logs (Nginx, Apache, custom logs)
    âœ”ï¸ Auto delete logs older than X days

ğŸ“Œ Default Config File Locations
ğŸ‘‰ Global config file:
ğŸ”— /etc/logrotate.conf

ğŸ‘‰ Service-specific configs:
ğŸ”— /etc/logrotate.d/

âœ… Example logrotate Configuration
ğŸ‘‰ Create a file:
ğŸ”— /etc/logrotate.d/myapp

ğŸ‘‰ Add:
ğŸ”— /var/log/myapp/*.log {
    daily
    rotate 7
    compress
    missingok
    notifempty
    create 0640 root root
}

âœ”ï¸ daily â†’ rotate logs every day
âœ”ï¸ rotate 7 â†’ keep last 7 logs
âœ”ï¸ compress â†’ compress old logs
âœ”ï¸ missingok â†’ ignore if file is missing
âœ”ï¸ notifempty â†’ donâ€™t rotate empty logs
âœ”ï¸ create â†’ create new log with permissions

ğŸ“Œ Run logrotate manually
ğŸ”— logrotate /etc/logrotate.conf


ğŸ”· Write a script to report the usage of AWS in your project?
!/bin/bash

##########
#Author :Ankur Verma
#Date : 20/11/2025

# Version : V1

# This script is about the resource checking of aws"
#####################################

#AWS S3
#AWS EC2
#AWS Lambda
#AWS IAM

# To run the script in debug mode
set -x

set -euo pipefail

# list s3 buckets
echo "Print list of s3 buckets"
aws s3 ls > resourceTracker

# list EC-2 instances
echo "Print list of ec-2"
aws ec2 describe-instances | jq '.Reservations[].Instances[].InstanceId' >> resourceT>

#list Lambda functions
echo "Print list of lambda functions"
aws lambda list-functions >> resourceTracker

#list IAM users
echo "Print list of IAM users"


ğŸ”· Script used to write the github uses listed in the collaborations
#!/bin/bash

helper()

set -x
set -euo pipefail

# Github API URL
API_URL="https://api.github.com"

# Github username and personal access token (must be exported in env)
USERNAME="$username"
TOKEN="$token"

# User and Repository information from command line args
REPO_OWNER="$1"
REPO_NAME="$2"

# Function to make a GET request to the Github API
function github_api_get() {
    local endpoint="$1"
    local url="${API_URL}/${endpoint}"

    # Send a GET request with authentication
    curl -s -u "${USERNAME}:${TOKEN}" "$url"
}

# Function to list users with read access
function list_users_with_read_access() {
    local endpoint="repos/${REPO_OWNER}/${REPO_NAME}/collaborators"

    # Fetch collaborators with read permission
    collaborators="$(github_api_get "$endpoint" | jq -r '.[] | select(.permissions.pull == true) | .login')"

    if [[ -z "$collaborators" ]]; then
        echo "No users with read access found for ${REPO_OWNER}/${REPO_NAME}."
    else
        echo "Users with read access to ${REPO_OWNER}/${REPO_NAME}:"
        echo "$collaborators"
    fi
}

# Helper function for argument validation
function helper() {
    expected_cmd_args=2
    if [ $# -ne $expected_cmd_args ]; then
        echo "Error: Missing required arguments."
        echo "Usage: $0 <repo-owner> <repo-name>"
        exit 1
    fi
}


# Main script
echo "Listing users with read access to ${REPO_OWNER}/${REPO_NAME}..."
list_users_with_read_access
echo "Done."

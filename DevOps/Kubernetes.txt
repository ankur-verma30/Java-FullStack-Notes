###################
ğŸ”· Orchestration
###################
Orchestration means automatically managing many things so that they work together correctly without manual effort.

ğŸ”„ Real-Life Analogy (Conceptual Understanding)
Think of an orchestra:
â¤ Many musicians (containers)
â¤ Different instruments (services)
â¤ A conductor (orchestrator)
â¤ Everyone plays at the right time, volume, and rhythm

ğŸ‘‰ Without a conductor â†’ chaos
ğŸ‘‰ With a conductor â†’ harmony


ğŸ”„ Why Orchestration is Needed
â¤ Modern applications: 
    âœ”ï¸ Are made of multiple microservices
    âœ”ï¸ Run on multiple machines
    âœ”ï¸ Must handle:
        âš¡ Failures
        âš¡ Traffic spikes
        âš¡ Updates without downtime

â¤ Manual management:
    âœ”ï¸ Is error-prone
    âœ”ï¸ Does not scale
    âœ”ï¸ Causes downtime
ğŸ‘‰ Orchestration removes manual work


ğŸ”„ What Exactly Does Orchestration Do?
Orchestration covers the full lifecycle of services:
1ï¸âƒ£ Deployment Management
â¤ Starts containers
â¤ Stops containers
â¤ Updates applications
â¤ Performs rolling updates

âœ… Example:
Deploy 3 instances of service-A

2ï¸âƒ£ Scheduling
â¤ Decides where to run containers
â¤ Picks best machine based on:
    âœ”ï¸ CPU
    âœ”ï¸ Memory
    âœ”ï¸ Availability
ğŸ‘‰ You donâ€™t choose machines manually.


3ï¸âƒ£ Scaling
â¤ Increase instances when traffic is high
â¤ Decrease instances when traffic is low

âœ… Example:
â¤ Scale from 3 â†’ 10 containers automatically


4ï¸âƒ£ Self-Healing
â¤ Restarts crashed containers
â¤ Recreates failed services
â¤ Moves workloads if a node fails
ğŸŒŸ System fixes itself automatically.


5ï¸âƒ£ Load Balancing
â¤ Distributes traffic across multiple instances
â¤ Prevents overload
âœ… Example:
Client â†’ Service â†’ Pod1 / Pod2 / Pod3


6ï¸âƒ£ Service Discovery
â¤ Services find each other automatically
â¤ No hardcoded IPs
âœ… Example: http://user-service


7ï¸âƒ£ Configuration & Secrets Management
â¤ Environment variables
â¤ Database credentials
â¤ API keys
ğŸ‘‰ Secure and centralized.


8ï¸âƒ£ Monitoring & Health Checks
â¤ Detects unhealthy services
â¤ Replaces bad instances


ğŸ”„ Orchestration in Container World
âŒ Without Orchestration (Docker Only)
âœ”ï¸ One host
âœ”ï¸ Manual scaling
âœ”ï¸ Manual restarts
âœ”ï¸ No health checks
âœ”ï¸ No coordination

âœ… With Orchestration (Kubernetes)
âœ”ï¸ Multi-node cluster
âœ”ï¸ Auto scaling
âœ”ï¸ Auto healing
âœ”ï¸ Load balancing
âœ”ï¸ Rolling updates
ğŸ‘‰ Kubernetes is a container orchestrator


âœ… Example: Without vs With Orchestration
ğŸ”„ Without vs With Orchestration
âŒ Without Orchestration
Server crashes â†’ App down
Traffic spike â†’ App slow
Container crashes â†’ Manual restart

âœ… With Orchestration
Server crashes â†’ App moved to another node
Traffic spike â†’ New containers created
Container crashes â†’ Auto restarted

7ï¸âƒ£ Orchestration vs Automation
| Automation            | Orchestration              |
| --------------------- | -------------------------- |
| Automates single task | Coordinates multiple tasks |
| Script-based          | System-based               |
| Local                 | Distributed                |
ğŸ‘‰ Orchestration is automation + coordination

ğŸ”„ Kubernetes as an Orchestrator
Kubernetes orchestrates:
âœ”ï¸ Pods
âœ”ï¸ Services
âœ”ï¸ Volumes
âœ”ï¸ Configurations
âœ”ï¸ Networking
ğŸ‘‰ You say: replicas: 3

âš¡ Kubernetes ensures:
âœ”ï¸ Always 3 running
âœ”ï¸ Restores if one fails
âœ”ï¸ Balances traffic
ğŸ‘‰ You declare what you want, Kubernetes decides how to achieve it


9ï¸âƒ£ Enterprise Perspective (Why Companies Need Orchestration)
â¤ High availability
â¤ Zero downtime
â¤ Cost optimization
â¤ Faster deployments
â¤ Resilient systems

âš¡ Thatâ€™s why:
â¤ Netflix
â¤ Google
â¤ Amazon
ğŸ‘‰ use orchestration platforms.


###############
ğŸ”· Kubernetes
###############
â“ What is Docker?
Docker is a containerization platform used to build, package, and run applications inside containers.


ğŸ”„ Key Role of Docker
â¤ Creates containers
â¤ Runs containers
â¤ Manages container lifecycle on a single machine
ğŸ‘‰ Docker is NOT an orchestration tool


ğŸ” Shortcomings of Docker
Docker is simple and minimalistic, which is good â€” but that simplicity causes limitations at scale.

1ï¸âƒ£ Single Host Limitation
âŒ Problem:
â¤ Docker by itself runs containers on one host
â¤ If the host machine goes down â†’ all containers go down

â—Impact:
â¤ No high availability
â¤ Not suitable for large distributed systems
ğŸ‘‰  Docker does not manage multiple machines


2ï¸âƒ£ Manual Scaling
âŒ Problem:
To scale containers, you must manually run:
ğŸ”— docker run ...
ğŸ”— docker run ...

â— Issues:
â¤ No auto-scaling
â¤ No CPU/memory-based scaling
â¤ Not practical in production


3ï¸âƒ£ No Self-Healing
âŒ Problem:
â¤ If a container crashes:
    âœ”ï¸ Docker does nothing automatically
    âœ”ï¸ Manual restart required

ğŸ”— docker ps
ğŸ”— docker restart <container>

â— Impact:
â¤ Downtime
â¤ Reliability issues


4ï¸âƒ£ No Built-in Load Balancing
âŒ Problem:
â¤ Docker does not distribute traffic automatically
â¤ You must configure external tools (Nginx, HAProxy)

â— Impact:
â¤ Extra configuration
â¤ Manual effort


5ï¸âƒ£ No Enterprise-Level Features
ğŸŒŸ Docker lacks:
    âœ”ï¸ Orchestration
    âœ”ï¸ Auto-scaling
    âœ”ï¸ Self-healing
    âœ”ï¸ Rolling updates
    âœ”ï¸ Service discovery
    âœ”ï¸ Fault tolerance
ğŸ‘‰ Docker is a container runtime, not a platform for large-scale distributed systems


ğŸ” Kubernetes
Kubernetes is a container orchestration platform that manages, scales, heals, and deploys containerized applications across a cluster of machines.
ğŸ‘‰ Kubernetes uses Docker (or other runtimes) underneath.


ğŸ”„ How Kubernetes Solves Dockerâ€™s Shortcomings
1ï¸âƒ£ Multi-Node Cluster Architecture
âŒ Docker Problem: Single host
âœ… Kubernetes Solution:
Kubernetes runs on a cluster of nodes

        Kubernetes Cluster
   ----------------------------
   | Master | Worker | Worker |
   ----------------------------

âœ”ï¸ Multiple machines
âœ”ï¸ High availability
âœ”ï¸ Fault tolerance
ğŸ‘‰ If one node fails â†’ workloads move to another node.


2ï¸âƒ£ Automatic Scaling (Replication Controller / ReplicaSet)
âŒ Docker Problem: Manual scaling
âœ… Kubernetes Solution:
â¤ ReplicaSet / Deployment
â¤ Maintains desired number of container replicas
ğŸ”— replicas: 3

ğŸ‘‰ If one container dies â†’ Kubernetes creates a new one

âš¡ Bonus:
â¤ Horizontal Pod Autoscaler (HPA)
â¤ Scales based on:
    âœ”ï¸ CPU
    âœ”ï¸ Memory
    âœ”ï¸ Metrics


3ï¸âƒ£Self-Healing
âŒ Docker Problem: No auto recovery
âœ… Kubernetes Solution: Kubernetes continuously monitors containers

â¤ If:
    âœ”ï¸ Container crashes â†’ restarted
    âœ”ï¸ Pod dies â†’ recreated
    âœ”ï¸ Node fails â†’ pods rescheduled
ğŸ‘‰ This is called self-healing


4ï¸âƒ£ Built-In Load Balancing
âŒ Docker Problem: No native load balancing
âœ… Kubernetes Solution:
â¤ Service object
â¤ Automatically load balances traffic across pods

Client â†’ Service â†’ Pod1 / Pod2 / Pod3
âœ”ï¸ No external tool required
âœ”ï¸ Internal & external traffic supported


ğŸ”„ Enterprise-Grade Orchestration Features
Kubernetes provides:
| Feature                  | Kubernetes |
| ------------------------ | ---------- |
| Rolling Updates          | âœ…         |
| Zero Downtime Deployment | âœ…         |
| Service Discovery        | âœ…         |
| Secrets & ConfigMaps     | âœ…         |
| Auto Scaling             | âœ…         |
| Self Healing             | âœ…         |
| RBAC & Security          | âœ…         |
ğŸ‘‰ This is why Kubernetes is production standard

ğŸ”„ Docker vs Kubernetes 
| Feature           | Docker           | Kubernetes         |
| ----------------- | ---------------- | ------------------ |
| Purpose           | Containerization | Orchestration      |
| Runs On           | Single host      | Multi-node cluster |
| Scaling           | Manual           | Automatic          |
| Self-Healing      | âŒ               | âœ…                |
| Load Balancing    | âŒ               | âœ…                |
| High Availability | âŒ               | âœ…                |
| Enterprise Ready  | âŒ               | âœ…                |

â— Kubernetes Does NOT Replace Docker
âœ”ï¸  Docker â†’ creates & runs containers
âœ”ï¸  Kubernetes â†’ manages & orchestrates containers
ğŸ“Œ They work together


############################
ğŸ”· Pods vs Node vs Cluster
############################
A Pod is the smallest deployable unit in Kubernetes that wraps one or more containers and shares network and storage.

â¤ Pod = wrapper around containers
â¤ Kubernetes never runs containers directly
â¤ Containers always run inside a Pod
â¤ Think of a Pod as: â€œA logical host for containersâ€


ğŸ”„ Key Characteristics of Pod
â¤ Smallest unit in Kubernetes
â¤ Usually contains one container
â¤ Containers in same Pod share:
    âœ”ï¸ IP address
    âœ”ï¸ Port space
    âœ”ï¸ Volumes


âœ… Pod Example
Pod
 â”œâ”€â”€ Container (Spring Boot App)
 â”œâ”€â”€ Shared Network (IP)
 â””â”€â”€ Shared Volume


ğŸ”„ Why Multiple Containers in a Pod
â¤ Sidecar pattern
â¤ Logging container
â¤ Monitoring container
âœ… Example:
â¤ App container
â¤ Log shipper container

Benifits of multiple containers in a Pod:
    âœ”ï¸ Shared lifecycle
    âœ”ï¸ Shared resources
    âœ”ï¸ Tight coupling


ğŸ”„ Node
A Node is a physical or virtual machine where Pods are scheduled and run.
Node = actual machine
Pods run on nodes
Node provides:
    âœ”ï¸ CPU
    âœ”ï¸ Memory
    âœ”ï¸ Network
    âœ”ï¸ Disk
ğŸ‘‰ Node is the worker machine

ğŸ”„ Components Inside a Node
Node
--------------------------------
| kubelet                       |
| container runtime             |
| kube-proxy                    |
--------------------------------
| Pods                          |
--------------------------------


ğŸ”„ Types of Nodes
| Node Type          | Purpose         |
| ------------------ | --------------- |
| Control Plane Node | Manages cluster |
| Worker Node        | Runs Pods       |


ğŸ”„ Node Failure
â¤ If node crashes:
    âœ”ï¸ Kubernetes moves pods to other nodes
    âœ”ï¸ Self-healing happens


ğŸ”„ Cluster
A Cluster is a group of nodes managed by Kubernetes that work together to run containerized applications.

â¤ Cluster = entire Kubernetes system
â¤ Includes:
    âœ”ï¸ Control plane
    âœ”ï¸ Multiple worker nodes
ğŸ‘‰ Users interact with the cluster, not individual nodes


ğŸ”„ Cluster Structure
Kubernetes Cluster
-------------------------------
| Control Plane               |
-------------------------------
| Worker Node | Worker Node  |
-------------------------------

ğŸ”„ Why Cluster?
âœ”ï¸ High availability
âœ”ï¸ Scalability
âœ”ï¸ Fault tolerance
âœ”ï¸ Load distribution


ğŸ”„ Relationship Between Pod, Node, and Cluster
Cluster
 â”œâ”€â”€ Node 1
 â”‚     â”œâ”€â”€ Pod A
 â”‚     â””â”€â”€ Pod B
 â”œâ”€â”€ Node 2
 â”‚     â””â”€â”€ Pod C
 â””â”€â”€ Node 3
       â””â”€â”€ Pod D

ğŸ”„ Hierarchy
Cluster > Node > Pod > Container


ğŸ”„ Pod vs Node vs Cluster
| Feature     | Pod           | Node             | Cluster             |
| ----------- | ------------- | ---------------- | ------------------- |
| What it is  | Smallest unit | Machine          | Collection of nodes |
| Contains    | Containers    | Pods             | Nodes               |
| Lifecycle   | Short-lived   | Long-lived       | Long-lived          |
| Managed by  | Kubernetes    | Kubernetes       | Kubernetes          |
| Scalability | Horizontal    | Add/remove nodes | Highly scalable     |


#####################
ğŸ”· K8s Architecture
#####################
1ï¸âƒ£ High-Level Overview
ğŸ“Œ What is Kubernetes Architecture?
Kubernetes follows a master-worker (control plane â€“ data plane) architecture, where:
    âœ”ï¸ Control Plane makes decisions
    âœ”ï¸ Worker Nodes run applications



ğŸ§± Cluster Structure
           Kubernetes Cluster
------------------------------------------------
|              Control Plane                   |
|----------------------------------------------|
| API Server | Scheduler | Controller Manager |
|            |           |                   |
|                 etcd                        |
------------------------------------------------
        |                 |                 |
------------------------------------------------
| Worker Node 1 | Worker Node 2 | Worker Node 3 |
------------------------------------------------
| kubelet | container runtime | kube-proxy     |
------------------------------------------------

ğŸ“Œ A cluster = Control Plane + Worker Nodes
2ï¸âƒ£ Control Plane (Master Node)
The control plane is the brain of Kubernetes.
ğŸ‘‰ It decides:
    âœ”ï¸ What should run
    âœ”ï¸ Where it should run
    âœ”ï¸ How to fix failures


ğŸ”„ API Server (kube-apiserver)
ğŸ“Œ Role: Entry point of Kubernetes cluster

ğŸ”„ Responsibilities:
â¤ Exposes Kubernetes REST API
â¤ Accepts all requests:
    âœ”ï¸ kubectl apply
    âœ”ï¸ kubectl get pods
â¤ Authenticates & validates requests
â¤ Talks to all other components
ğŸ“Œ All communication goes through API Server


2ï¸âƒ£ etcd (Key-Value Store)
ğŸ“Œ Role: Database of Kubernetes
â¤ Stores:
    âœ”ï¸ Cluster state
    âœ”ï¸ Pod info
    âœ”ï¸ Node info
    âœ”ï¸ ConfigMaps
    âœ”ï¸ Secrets
ğŸ“Œ If etcd is lost â†’ cluster state is lost
ğŸ“Œ etcd must be backed up


3ï¸âƒ£ Scheduler (kube-scheduler)
ğŸ“Œ Role: Decides where a pod should run

ğŸ”„ How Scheduler Works:
â¤ Looks for:
    âœ”ï¸ CPU availability
    âœ”ï¸ Memory availability
    âœ”ï¸ Node health
â¤ Chooses the best node
ğŸ“Œ Scheduler does not run pods, it only assigns nodes


4ï¸âƒ£ Controller Manager
ğŸ“Œ Role: Ensures desired state = actual state

Runs multiple controllers:
| Controller            | Function                |
| --------------------- | ----------------------- |
| Node Controller       | Detects node failure    |
| ReplicaSet Controller | Maintains pod count     |
| Deployment Controller | Handles rolling updates |
| Job Controller        | Manages batch jobs      |
ğŸ“Œ If something goes wrong â†’ controllers fix it


ğŸ”„ Worker Node Architecture (Where Apps Run)
Worker nodes are where your containers actually run.

ğŸ”„ Components Inside Worker Node
Worker Node
-----------------------------------
| kubelet                          |
| container runtime (Docker/CRI)   |
| kube-proxy                       |
-----------------------------------


1ï¸âƒ£ kubelet
ğŸ“Œ Role: Agent running on each worker node

ğŸ”„ Responsibilities:
â¤ Talks to API Server
â¤ Starts/stops containers
â¤ Reports node health
â¤ Ensures pod is running as expected
ğŸ“Œ kubelet = node manager


2ï¸âƒ£ Container Runtime
ğŸ“Œ Role: Runs containers

âœ… Examples:
Docker (older)
containerd
CRI-O

ğŸ“Œ Kubernetes does not run containers directly
ğŸ“Œ It uses CRI (Container Runtime Interface)


3ï¸âƒ£ kube-proxy
ğŸ“Œ Role: Handles networking & load balancing

ğŸ”„ Responsibilities:
â¤ Routes traffic to correct pods
â¤ Implements Services
â¤ Maintains iptables rules

ğŸ‘‰ kube-proxy enables:
ğŸ”— Service â†’ Pod1 / Pod2 / Pod3


ğŸ”„ How a Pod is Created (Request Flow)
âœ… Example:
ğŸ”— kubectl apply -f deployment.yaml

ğŸ”„ Step-by-Step Flow
1ï¸âƒ£ Request goes to API Server
2ï¸âƒ£ API Server validates request
3ï¸âƒ£ Object stored in etcd
4ï¸âƒ£ Scheduler selects node
5ï¸âƒ£ kubelet on selected node:
    âœ”ï¸ Pulls image
    âœ”ï¸ Starts container
6ï¸âƒ£ kube-proxy enables networking
7ï¸âƒ£ Pod becomes Running
ğŸ‘‰ Everything is automated


ğŸ”„ How Kubernetes Handles Failure (Recovery Flow)
1ï¸âƒ£ Container Crash
â¤ kubelet detects failure
â¤ Restarts container

2ï¸âƒ£ Pod Crash
â¤ Controller recreates pod

3ï¸âƒ£ Node Crash
â¤ Node Controller detects failure
â¤ Pods rescheduled to healthy nodes
ğŸ‘‰ This is self-healing

6ï¸âƒ£ Control Plane vs Worker Node
| Control Plane   | Worker Node       |
| --------------- | ----------------- |
| Manages cluster | Runs applications |
| Decision making | Execution         |
| API Server      | kubelet           |
| Scheduler       | container runtime |
| Controllers     | kube-proxy        |


ğŸ”„ Why This Architecture is Powerful
âœ”ï¸ Separation of concerns
âœ”ï¸ Highly scalable
âœ”ï¸ Fault tolerant
âœ”ï¸ Declarative system
âœ”ï¸ Cloud-agnostic


####################################
ğŸ”· Kubernetes Production Systems
####################################
A Kubernetes distribution is a packaged version of Kubernetes that includes the core Kubernetes components plus additional tools, configurations, security features, and integrations to make Kubernetes production-ready.

â¤ Kubernetes (upstream) = raw engine
â¤ Distribution = engine + safety + automation + enterprise tools

ğŸ“Œ Think of it like:
â¤ Linux kernel â†’ Ubuntu / RedHat / CentOS
â¤ Kubernetes core â†’ OpenShift / EKS / GKE / AKS

ğŸ”„ Why Distributions Exist?
âš¡ Upstream Kubernetes:
â¤ Hard to install
â¤ Hard to secure
â¤ Hard to upgrade
â¤ Hard to operate at scale

âš¡ Distributions solve:
â¤ Installation
â¤ Security
â¤ Monitoring
â¤ Networking
â¤ Upgrades
â¤ Cloud integration

ğŸ”„ Popular Kubernetes Distributions (Production Use)
Order you provided (âœ” correct) â€” explained one by one
1ï¸âƒ£ Kubernetes (Upstream / Vanilla K8s)
â¤ Core open-source Kubernetes
â¤ Maintained by CNCF
â¤ Used when:
    âœ”ï¸ Learning
    âœ”ï¸ Custom platforms
    âœ”ï¸ Internal tooling

â¤ Limitations:
    âœ”ï¸ No built-in UI
    âœ”ï¸ No enterprise security
    âœ”ï¸ Manual upgrades
    âœ”ï¸ Manual cluster management

2ï¸âƒ£ Red Hat OpenShift
Enterprise Kubernetes with opinionated security & developer tools
ğŸŒŸ Key Features
â¤ Built-in CI/CD
â¤ Built-in container registry
â¤ Strict security (non-root containers)
â¤ Web console
â¤ Enterprise support

ğŸŒŸ Used by
â¤ Banks
â¤ Telecom
â¤ Enterprises
ğŸ“Œ OpenShift = Kubernetes + enterprise guardrails

3ï¸âƒ£ Rancher
Kubernetes management platform (not just a cluster)
ğŸŒŸ Key Features
â¤ Manage 100s of clusters
â¤ Multi-cloud support
â¤ Centralized UI
â¤ RBAC across clusters

ğŸ“Œ Rancher does not replace Kubernetes, it manages Kubernetes

4ï¸âƒ£ VMware Tanzu
Enterprise Kubernetes for VMware environments
ğŸŒŸ Key Features
â¤ Deep vSphere integration
â¤ Kubernetes inside VMware infra
â¤ Hybrid cloud support

ğŸŒŸ Used by
Enterprises already using VMware

5ï¸âƒ£ EKS (Amazon Elastic Kubernetes Service)
Fully managed Kubernetes control plane by AWS

AWS manages
    âœ”ï¸ API server
    âœ”ï¸ etcd
    âœ”ï¸ Control plane HA
    âœ”ï¸ Security patches

You manage
    âœ”ï¸ Worker nodes
    âœ”ï¸ Pods
    âœ”ï¸ Networking
    âœ”ï¸ Scaling

6ï¸âƒ£ AKS (Azure Kubernetes Service)
Managed Kubernetes on Azure
ğŸŒŸ Key Features
    âœ”ï¸ Azure AD integration
    âœ”ï¸ Azure Monitor
    âœ”ï¸ Azure networking

7ï¸âƒ£ GKE (Google Kubernetes Engine)
Googleâ€™s managed Kubernetes (most mature)

Why GKE is specialâ“
    âœ”ï¸ Kubernetes created by Google
    âœ”ï¸ Best auto-scaling
    âœ”ï¸ Best networking
    âœ”ï¸ Very stable

ğŸ”„ Difference Between Kubernetes ğŸ†š EKS
| Feature          | Kubernetes (Upstream) | EKS           |
| ---------------- | --------------------- | ------------- |
| Control Plane    | You manage            | AWS manages   |
| Installation     | Manual                | Automated     |
| HA               | Manual                | Built-in      |
| Upgrades         | Manual                | One-click     |
| Security         | DIY                   | AWS IAM       |
| Cost             | Free                  | Pay AWS infra |
| Production-ready | Hard                  | Easy          |


ğŸ”„ How DevOps Engineers Manage Hundreds of Kubernetes Clusters?
They donâ€™t manage clusters manually â€” they automate everything.

ğŸŒŸ Tools Used
1ï¸âƒ£ kops (Kubernetes Operations)
ğŸ“Œ Used for:
    âœ”ï¸ Creating production clusters on AWS
    âœ”ï¸ Managing cluster lifecycle

Features:
    âœ”ï¸ Cluster creation
    âœ”ï¸ Auto-scaling
Upgrade support

2ï¸âƒ£ kubeadm
ğŸ“Œ Used for:
    âœ”ï¸ Bootstrapping Kubernetes clusters
    âœ”ï¸ Mostly for on-prem or custom infra

âŒ Not for managing 100s of clusters alone

3ï¸âƒ£ Rancher / OpenShift / Tanzu
ğŸ“Œ Centralized management:
    âœ”ï¸ Single dashboard
    âœ”ï¸ RBAC
    âœ”ï¸ Policies
    âœ”ï¸ Cluster visibility


################################################
ğŸ”· Installation of Kubernetes using KOPS on EC2
################################################
Kops (Kubernetes Operations) is a tool used to create, upgrade, and manage production-grade Kubernetes clusters on cloud providers like AWS.

â“ Why Kops Exists?
Installing Kubernetes manually on EC2 is:
    âœ”ï¸ Complex
    âœ”ï¸ Error-prone
    âœ”ï¸ Not production-safe

ğŸ“Œ Kops automates everything:
    âœ”ï¸ EC2 instances
    âœ”ï¸ VPC
    âœ”ï¸ Auto Scaling Groups
    âœ”ï¸ Load Balancers
    âœ”ï¸ IAM roles
    âœ”ï¸ etcd

Kubernetes control plane

ğŸ”„ Where Kops Fits in Kubernetes World
| Tool    | Purpose                          |
| ------- | -------------------------------- |
| kubeadm | Bootstrap Kubernetes (low-level) |
| kops    | Production cluster lifecycle     |
| EKS     | Fully managed Kubernetes         |
| Rancher | Manage many clusters             |

ğŸ“Œ Kops â‰  Kubernetes
ğŸ“Œ Kops = Cluster lifecycle manager

ğŸ”„ High-Level Architecture
AWS S3 (State Store)
      â†“
Kops CLI
      â†“
AWS APIs
      â†“
EC2 + VPC + ASG + ELB
      â†“
Kubernetes Cluster

ğŸ”„ Prerequisites
This approach installs Kubernetes using KOPS, which is a production-grade Kubernetes lifecycle management tool for AWS.
You can perform this either on:
â¤ An EC2 instance (recommended for AWS-based setup), or
â¤ Your personal laptop (Linux preferred).


ğŸ”„ Dependencies Required (Why they are needed)
1ï¸âƒ£ Python3: Required internally by AWS CLI and some automation scripts.
2ï¸âƒ£ AWS CLI: Allows your system to talk to AWS and create resources like EC2, VPC, S3, IAM, etc.
3ï¸âƒ£ kubectl: Command-line tool used to interact with the Kubernetes cluster once it is created.
4ï¸âƒ£ KOPS: The main tool that creates, updates, validates, and deletes Kubernetes clusters on AWS.


ğŸ”„ Installing kubectl (Updated Kubernetes Repository â€“ Change Highlighted)
ğŸ” What changed?
â¤ Earlier, kubectl was installed from deprecated Google repos
â¤ Now Kubernetes uses pkgs.k8s.io, which is the official, secure repository

âœ… Explanation of commands:
ğŸ”— sudo apt-get update
ğŸ”— sudo apt-get install -y ca-certificates curl apt-transport-https
ğŸ‘‰ These packages allow secure communication (HTTPS) and repository access.

ğŸ”— curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key \
| sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
â¤ Downloads Kubernetes signing key
â¤ Converts it into a secure keyring format (modern Ubuntu requirement)

ğŸ”— echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] \
https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' \
| sudo tee /etc/apt/sources.list.d/kubernetes.list
ğŸ‘‰ Adds Kubernetes v1.28 repository to your system

ğŸ”— sudo apt-get update
ğŸ”— sudo apt-get install -y kubectl
ğŸ‘‰ Installs kubectl safely from the official repo

ğŸ“Œ Why v1.28?
â¤ Stable
â¤ Production-tested
â¤ Compatible with recent KOPS releases


ğŸ”„ Installing AWS CLI (Ubuntu 24.04 Compatible)
ğŸ” What changed?
â¤ Older apt-based AWS CLI installs often break on Ubuntu 24.04
â¤ Snap-based installation is now recommended

ğŸ”— sudo snap install aws-cli --classic

â¤ Installs AWS CLI v2 (latest)
â¤ --classic allows full system access
ğŸ”— export PATH="$PATH:/home/ubuntu/.local/bin/"

ğŸ‘‰ Ensures AWS CLI is accessible from terminal


ğŸ”„ Installing KOPS (Latest Stable Release)
curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s \
https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64

â¤ Dynamically fetches latest stable KOPS version
â¤ Avoids hardcoding versions (production best practice)

ğŸ”— chmod +x kops-linux-amd64
ğŸ”— sudo mv kops-linux-amd64 /usr/local/bin/kops
ğŸ‘‰ Makes KOPS executable system-wide


ğŸ”„ IAM Permissions (Why they are required)
â¤ KOPS creates AWS infrastructure, so it must call AWS APIs.

Required permissions:
    âœ”ï¸ AmazonEC2FullAccess â†’ create EC2 instances
    âœ”ï¸ AmazonS3FullAccess â†’ store cluster state
    âœ”ï¸ IAMFullAccess â†’ create roles & policies
    âœ”ï¸ AmazonVPCFullAccess â†’ networking resources
ğŸ“Œ If you use Admin user, these are already included.

ğŸ”„ Configure AWS CLI
ğŸ”— aws configure

â¤ This command stores:
    âœ”ï¸ AWS Access Key
    âœ”ï¸ Secret Key
    âœ”ï¸ Default region (example: us-east-1)
    âœ”ï¸ Output format
ğŸ“Œ From this point onward, all KOPS commands interact with AWS automatically.


ğŸ”„ Create S3 Bucket (KOPS State Store)
ğŸ”— aws s3api create-bucket --bucket kops-abhi-storage --region us-east-1

â“ Why S3 is mandatory?
â¤ KOPS stores cluster configuration, secrets, certificates
â¤ Acts as the single source of truth for the cluster
â¤ Enables cluster updates, recovery, and deletion


ğŸ”„ Create the Kubernetes Cluster (Configuration Phase)
ğŸ”— kops create cluster \
--name=demok8scluster.k8s.local \
--state=s3://kops-abhi-storage \
--zones=us-east-1a \
--node-count=1 \
--node-size=t2.micro \
--master-size=t2.micro \
--master-volume-size=8 \
--node-volume-size=8

â“ What this command actually does:
â¤ Creates cluster definition only
â¤ Stores it in S3
â¤ Does NOT create EC2 instances yet

ğŸ“Œ .k8s.local indicates:
â¤ Gossip-based DNS
â¤ Suitable for learning/demo
â¤ No Route53 required


ğŸ”„ Edit Cluster Configuration (Very Important Step)
ğŸ”— kops edit cluster demok8scluster.k8s.local

â“ Why this step is emphasized?
â¤ Default KOPS config may create:
    âœ”ï¸ Multiple master nodes
    âœ”ï¸ Larger instance sizes
    âœ”ï¸ Extra networking components

ğŸ“Œ Editing ensures:
    âœ”ï¸ Free-tier friendly resources
    âœ”ï¸ Controlled AWS billing
    âœ”ï¸ Production tuning when required


ğŸ”„ Build the Cluster (Actual Infrastructure Creation)
kops update cluster demok8scluster.k8s.local --yes --state=s3://kops-abhi-storage

â“ What happens internally:
    âœ”ï¸ EC2 instances are launched
    âœ”ï¸ Kubernetes control plane is installed
    âœ”ï¸ Worker nodes join the cluster
    âœ”ï¸ IAM roles and networking are configured
    âœ”ï¸ kubeconfig is generated automatically
â³ Takes 5â€“15 minutes


ğŸ”„ Validate the Cluster
ğŸ”— kops validate cluster demok8scluster.k8s.local

â“ What this checks:
    âœ”ï¸ Master node health
    âœ”ï¸ Worker node readiness
    âœ”ï¸ Kubernetes API accessibility
    âœ”ï¸ DNS and networking

âœ… Expected output:
ğŸ‘‰ Your cluster demok8scluster.k8s.local is ready

#############################################
ğŸ”· Deploy application using Kubernetes Pods
#############################################
ğŸ”„ In Kubernetes, deploying an application means:
â¤ Running your application inside a container
â¤ Scheduling that container inside a Pod
â¤ Allowing Kubernetes to manage its lifecycle
ğŸ“Œ Pod is the smallest deployable unit in Kubernetes.


ğŸ”„ Prerequisites (Before deployment)
You must have:
â¤ A running Kubernetes cluster
â¤ kubectl configured and connected to the cluster
â¤ Your application available as a container image (Docker image)

âœ… Example image:
nginx
mycompany/spring-boot-app:1.0

ğŸ”„ Need of Pod
â¤ Wraps one or more containers
â¤ Provides:
    âœ”ï¸ Same network (IP & port)
    âœ”ï¸ Shared storage
    âœ”ï¸ Shared lifecycle
ğŸ“Œ Even if you run one container, Kubernetes still runs it inside a Pod.


ğŸ”„ Ways to deploy an application using Pods
ğŸ‘‰ Two common ways
1ï¸âƒ£ Imperative (Quick test)
2ï¸âƒ£ Declarative (Recommended / Production)

ğŸ”„ Imperative Way (Quick & Temporary)
kubectl run my-app-pod --image=nginx --port=80

â“What happens?
â¤ Kubernetes creates a Pod
â¤ Pulls the image
â¤ Starts the container

ğŸ“Œ Not recommended for production
â¤ No version control
â¤ Hard to manage changes


ğŸ”„ Declarative Way (Recommended)
You define a YAML file describing the Pod.

ğŸ”— Pod Definition File (pod.yaml)
apiVersion: v1
kind: Pod
metadata:
  name: my-app-pod
  labels:
    app: my-app
spec:
  containers:
  - name: my-container
    image: nginx
    ports:
    - containerPort: 80


âœ… Explanation of Each Section
1ï¸âƒ£ apiVersion & kind
â¤ Tells Kubernetes what type of object this is
â¤ Pod belongs to API version v1

2ï¸âƒ£ metadata
â¤ name: Unique name of the Pod
â¤ labels: Used for identification and grouping

3ï¸âƒ£ spec
â¤ Defines how the Pod should run

4ï¸âƒ£ containers
â¤ List of containers inside the Pod
â¤ image: Docker image to run
â¤ containerPort: Port exposed inside container
ğŸ“Œ Kubernetes does not expose this port outside automatically


ğŸ”„ Deploy the Pod
ğŸ”— kubectl apply -f pod.yaml

â“ What happens?
â¤ Kubernetes reads the YAML
â¤ Schedules the Pod on a Node
â¤ Pulls image and starts container


ğŸ”„ Verify Pod Status
ğŸ”— kubectl get pods

ğŸ‘‰ Expected states:
    âœ”ï¸ Pending
    âœ”ï¸ Running
    âœ”ï¸ CrashLoopBackOff (if error)


ğŸ”„ View Pod Details
ğŸ”— kubectl describe pod my-app-pod

ğŸ‘‰ Shows:
    âœ”ï¸ Node assignment
    âœ”ï¸ Container state
    âœ”ï¸ Events (errors if any)


ğŸ”„ Access the Application
â¤ Pods are not accessible from outside by default.

â¤ Temporary access (for testing):
ğŸ”— kubectl port-forward pod/my-app-pod 8080:80

â¤ Access:
ğŸ”— http://localhost:8080


ğŸ”„ Logs of the Application
ğŸ”— kubectl logs my-app-pod

If multiple containers:
ğŸ”— kubectl logs my-app-pod -c my-container


ğŸ”„ Why Pods are NOT used directly in Production?
Pods:
    âœ”ï¸ Die easily
    âœ”ï¸ No auto-restart guarantee
    âœ”ï¸ No scaling
    âœ”ï¸ No self-healing

ğŸ“Œ Thatâ€™s why we use:
    âœ”ï¸ Deployment
    âœ”ï¸ ReplicaSet
    âœ”ï¸ StatefulSet

ğŸ”„ Production Flow
Docker Image
   â†“
Deployment
   â†“
ReplicaSet
   â†“
Pods

ğŸ‘‰ Pods are created and managed automatically.

ğŸ”„ Pod Deletion
ğŸ”— kubectl delete pod my-app-pod
ğŸ‘‰ Pod is permanently removed.


#################################################
âš¡ kubectl cheatsheet to refer any commands
#################################################


###########################
ğŸ”· Kubernetes Deployment
###########################
A Deployment is a higher-level Kubernetes object used to:
â¤ Deploy applications
â¤ Keep them running
â¤ Scale them
â¤ Update them without downtime
ğŸ‘‰ You never manage Pods directly in production â€” Deployments do that for you.

â¤ Deployment = Manager of Pods
âœ… You tell Kubernetes:
    âœ”ï¸  Which image to run
    âœ”ï¸  How many replicas you want
    âœ”ï¸  How updates should happen
â¤ Kubernetes ensures that desired state = actual state.


â“What problems does Deployment solve?
ğŸŒŸ Without Deployment:
    âœ”ï¸ Pod crashes â†’ app goes down
    âœ”ï¸ No scaling
    âœ”ï¸ No rolling updates
    âœ”ï¸ Manual recovery

ğŸŒŸ With Deployment:
    âœ”ï¸ Pods auto-restart
    âœ”ï¸ Auto scaling
    âœ”ï¸ Rolling updates
    âœ”ï¸ Rollback support


ğŸ”„ Internal Working 
Deployment
   â†“
ReplicaSet
   â†“
Pods
   â†“
Containers

â¤ Deployment defines the desired state
â¤ ReplicaSet maintains pod count
â¤ Pods run containers


ğŸ”„  Difference: Container ğŸ†š Pod ğŸ†š Deployment
| Feature         | Container           | Pod                      | Deployment                   |
| --------------- | ------------------- | ------------------------ | ---------------------------- |
| Definition      | Application runtime | Wrapper for container(s) | Controller that manages Pods |
| Smallest unit   | âŒ                   | âœ…                        | âŒ                            |
| Runs directly   | Yes (Docker)        | Yes (K8s)                | No                           |
| Contains        | App + dependencies  | One or more containers   | Pod template                 |
| IP Address      | âŒ                   | âœ… (one per Pod)          | âŒ                            |
| Scaling         | âŒ                   | âŒ                        | âœ…                            |
| Self-healing    | âŒ                   | âŒ                        | âœ…                            |
| Rolling updates | âŒ                   | âŒ                        | âœ…                            |
| Rollback        | âŒ                   | âŒ                        | âœ…                            |
| Production use  | âŒ                   | âŒ                        | âœ…                            |


ğŸ”„ Container (Lowest Level)
â¤ Created using Docker/CRI
â¤ Contains:
    âœ”ï¸ Application
    âœ”ï¸ Libraries
    âœ”ï¸ Runtime dependencies
â¤ No networking or orchestration logic
ğŸ“Œ Container alone is not production-ready


ğŸ”„ Pod (Kubernetes Runtime Unit)
â¤ Smallest deployable unit in Kubernetes
â¤ Wraps:
    âœ”ï¸ One or more containers
â¤ Provides:
    âœ”ï¸ Shared IP
    âœ”ï¸ Shared storage
    âœ”ï¸ Shared lifecycle
ğŸ“Œ Pods are ephemeral (temporary)


ğŸ”„ Deployment (Production-Grade Object)
â¤ Manages Pods via ReplicaSet
â¤ Ensures:
    âœ”ï¸ Desired number of replicas
    âœ”ï¸ Zero-downtime deployments
    âœ”ï¸ Automatic restarts
    âœ”ï¸ Version rollback
ğŸ“Œ Most commonly used Kubernetes object


âœ… Example
ğŸ”— Deployment YAML (nginx)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80


ğŸ”„ What happens when you apply this?
ğŸ”— kubectl apply -f deployment.yaml

Kubernetes:
    âœ”ï¸ Creates a Deployment
    âœ”ï¸ Creates a ReplicaSet
    âœ”ï¸ Creates 3 Pods
    âœ”ï¸ Keeps them running always


ğŸ”„ Real-World Analogy 
| Kubernetes | Real Life        |
| ---------- | ---------------- |
| Container  | Machine          |
| Pod        | Room             |
| Deployment | Building manager |


ğŸ”‘ Takeaways
â¤ Container â†’ runs app
â¤ Pod â†’ runs container(s)
â¤ Deployment â†’ manages Pods
â¤ Never deploy Pods directly in production
â¤ Deployment = scaling + self-healing + rolling updates



##############################################################
KUBERNETES SERVICES | DISCOVERY | LOAD BALANCING | NETWORKING
##############################################################
================================
ğŸ”· Hospital Management System
================================
ğŸ”„ Pitch Deck
Hi, I built a Hospital Management System to digitize and streamline hospital operations like user management, patient records, appointment scheduling, billing, and pharmacy workflows. The main goal of this project is to reduce manual work, avoid appointment conflicts, maintain accurate medical history, and improve overall hospital efficiency.

The system supports role-based access control, where different roles such as admin, doctor, patient etc have different permissions. The Admin can create, update, and manage users like doctors, nurses, staff, and patients, and assign roles to ensure secure access.

The Doctor module allows doctors to manage their schedules, view assigned appointments, and access patient medical records for diagnosis and treatment planning.

The Patient module allows patients to view their personal medical history, track appointment history, and also book, reschedule, or cancel appointments.
For Patient Management, I implemented a complete registration workflow where patient details like demographics, insurance, and emergency contacts are stored. The system maintains medical records including patient history, diagnosis, prescriptions, and uploaded test reports, making it easier for doctors to access everything in one place.

For Appointment Scheduling, I built a booking system with doctor availability and slot-based scheduling. Each appointment has a status like Scheduled, Completed, or Cancelled, and the system checks slot availability to avoid double booking.

For Billing and Invoicing, the system generates invoices for consultations, tests, and treatments, and also tracks payments, dues, and history. I also planned the design to support third-party payment gateway integration.

Additionally, I built Pharmacy Management with inventory tracking, low-stock and expiry alerts, and prescription linking so medicines can be mapped to patient prescriptions.

Currently, Laboratory Management and Reporting/Analytics dashboards are under development, and the next step is to integrate test workflows and generate operational insights like revenue and appointment trends.


ğŸ”„ ğŸš« Problems Faced While Building HMS
1ï¸âƒ£ Role-Based Access Control (RBAC) Complexity
â¤ Deciding who can access what (Admin vs Doctor vs Patient vs Staff)
â¤ Preventing unauthorized actions like:
â¤ Patient editing other patient records
â¤ Doctor accessing non-assigned patients
â¤ Implementing permissions cleanly without duplicating code
ğŸ‘‰ â€œHandling RBAC properly was challenging because security and data privacy are critical in hospital systems.â€


2ï¸âƒ£ Appointment Slot Conflicts & Double Booking
â¤ Preventing 2 patients from booking the same doctor + same time slot
â¤ Handling cases like:
    âœ”ï¸ Reschedule overlap
    âœ”ï¸ Cancel and re-book logic
    âœ”ï¸ Ensuring appointment status transitions are consistent
    (Scheduled â†’ Completed / Cancelled)
ğŸ‘‰ â€œThe biggest challenge was making appointment scheduling reliable and conflict-free.â€


3ï¸âƒ£ Database Design + Relationship Management
Designing tables and relationships for:
    âœ”ï¸Users â†” Patients â†” Doctors â†” Appointments â†” Billing â†” Prescriptions
    âœ”ï¸Avoiding redundancy and ensuring data integrity using:
    âœ”ï¸Primary keys, foreign keys
    âœ”ï¸Unique constraints
    âœ”ï¸Handling updates without breaking references
ğŸ‘‰ â€œGetting the schema right was important because everything depends on patient and appointment data.â€


4ï¸âƒ£ Maintaining Accurate Medical Records & File Upload Handling
â¤ Managing structured data (diagnosis, treatment plans) + files (reports, prescriptions)
â¤ ğŸš« Problems like:
    âœ”ï¸ File storage location decision
    âœ”ï¸ Linking reports to the correct patient & visit
    âœ”ï¸ Validations (file size/type) and safe uploads
ğŸ‘‰ â€œMedical records require correctness and traceability, so file management was a key challenge.â€


5ï¸âƒ£ Billing Calculation + Payment Tracking Accuracy
Generating correct invoices based on:
â¤ Consultation fees
â¤ Tests/treatments
â¤ Pharmacy medicines
â¤ Tracking partial payments, pending dues, payment history
â¤ Avoiding mismatches between bill and services used
ğŸ‘‰ â€œBilling required careful validation because even small mistakes impact trust and finance.â€


6ï¸âƒ£ Validations + Error Handling Across Modules
â¤ Handling invalid inputs, empty fields, wrong IDs
â¤ Showing meaningful errors instead of app crash
â¤ Preventing inconsistent states (like booking without patient record)


ğŸ”„ Top 3 Future Features to Add
1ï¸âƒ£ Lab + Report Module (End-to-End Integration)
â¤ Doctors can raise lab test requests
â¤ Lab staff can upload results
â¤ Patients can view/download reports
â¤ Reports auto-linked to medical records + billing
ğŸ‘‰ Completes the patient treatment cycle + adds real hospital workflow.


2ï¸âƒ£ Advanced Analytics Dashboard (Admin + Department Level)
Track:
    âœ”ï¸ Daily/weekly patient inflow
    âœ”ï¸ Doctor-wise appointment load
    âœ”ï¸ Revenue trends & pending dues
    âœ”ï¸ Department performance
    âœ”ï¸ Filters by date range / doctor / department
ğŸ‘‰ Adds decision-making power for management.


3ï¸âƒ£ Smart Notifications + Reminders (SMS/Email + WhatsApp)
â¤ Appointment reminders before visit time
â¤ Billing due alerts
â¤ Prescription refill reminders
â¤ Emergency notifications (optional)
ğŸ‘‰ Improves patient experience + reduces missed appointments.



ğŸ”„ How I Prioritize Features
prioritize features based on Impact + Urgency + Effort + Risk.
1ï¸âƒ£ Business Impact / User Value
â¤ Which feature improves patient care, hospital operations, or revenue the most?
â¤ Example: Appointment + Billing has high impact â†’ top priority


2ï¸âƒ£ Critical Workflow Dependency
â¤ Features that unblock other modules come first
âœ… Example: User + RBAC â†’ Patient â†’ Appointment â†’ Billing
(because billing depends on appointments)


3ï¸âƒ£ Frequency of Use (Daily Usage)
â¤ Features used daily should be built first

âœ… Example:
    âœ”ï¸ Appointment booking = daily
    âœ”ï¸ Analytics dashboard = weekly/monthly


4ï¸âƒ£ Risk & Complexity
High-risk features should be done earlier to avoid surprises later
âœ… Example:
    âœ”ï¸ Payment gateway integration
    âœ”ï¸ Role-based security
    âœ”ï¸ File uploads


ğŸ”„ Best Priority Order for Your HMS
P0ï¸âƒ£ (Must Have / Core System)
â¤ User Management + RBAC
â¤ Patient Registration + Medical Records
â¤ Appointment Scheduling


P1ï¸âƒ£ (Revenue & Operations)
â¤ Billing + Payment Tracking
â¤ Pharmacy Inventory + Prescription integration


P2ï¸âƒ£ (Enhancements)
â¤ Notifications + Reminders
â¤ Analytics Dashboard


#######################################
ğŸ”·AWS Deployment Architecture for HMS
#######################################
Hospital Management System will be deployed as containerized microservices on AWS using:
1ï¸âƒ£ Docker for containerization
2ï¸âƒ£ Amazon EKS (Elastic Kubernetes Service) for orchestration
3ï¸âƒ£ Jenkins for CI/CD pipeline
4ï¸âƒ£ GitHub for source code management


ğŸ”„ AWS Infrastructure Components
1ï¸âƒ£ Core Services
â¤ Amazon EKS(Elastic Kubernetes Service) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Managed Kubernetes cluster for running your microservices
â¤ Amazon ECR(Elastic Container Registry) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Private Docker container registry for storing images
â¤ Amazon RDS(Relational Database Service) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Managed MySQL database for persistent data
â¤ Amazon ElastiCache â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Redis for session management and caching
â¤ Amazon S3(Simple Storage Service) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Storage for medical reports, test results, and backups


2ï¸âƒ£ Networking
â¤ VPC â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Isolated network for your infrastructure
â¤ Public Subnets â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ For load balancers and NAT gateways
â¤ Private Subnets â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ For EKS nodes and RDS databases
â¤ Application Load Balancer â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ For routing traffic to services
â¤ NAT Gateway â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ For outbound internet access from private subnets


3ï¸âƒ£ Security & Monitoring
â¤ AWS IAM â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Role-based access control
â¤ AWS Secrets Manager â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ For storing database credentials and API keys
â¤ Amazon CloudWatch â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Logging and monitoring
â¤ AWS WAF â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Web application firewall for API protection



ğŸ”„ Microservices Architecture
Based on your requirements, here's the microservice breakdown:
Core Microservices
â¤ User Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ User management, authentication, authorization
â¤ Patient Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Patient registration, medical records
â¤ Appointment Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Scheduling, booking, availability management
â¤ Billing Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Invoice generation, payment tracking
â¤ Pharmacy Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Inventory, prescription management
â¤ Laboratory Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Test management, results tracking
â¤ Notification Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Email, SMS, Kafka-based notifications
â¤ Communication Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ WebSocket-based chat system
â¤ API Gateway â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Single entry point, routing, rate limiting

Supporting Services
â¤ Config Server - Centralized configuration management
â¤ Service Discovery - Eureka or AWS Cloud Map for service registration


ğŸ”„ Deployment Steps
Phase 1ï¸âƒ£: AWS Infrastructure Setup
1ï¸âƒ£ VPC Configuration
â¤ Create VPC with CIDR block (e.g., 10.0.0.0/16)
â¤ Create 3 public subnets across availability zones
â¤ Create 3 private subnets across availability zones
â¤ Set up Internet Gateway for public subnets
â¤ Configure NAT Gateways for private subnet internet access
â¤ Create route tables and associate with subnets


2ï¸âƒ£ Security Groups
â¤ ALB Security Group: Allow HTTP (80), HTTPS (443) from internet
â¤ EKS Node Security Group: Allow traffic from ALB, inter-node communication
â¤ RDS Security Group: Allow MySQL (3306) only from EKS nodes
â¤ Redis Security Group: Allow Redis (6379) only from EKS nodes


3ï¸âƒ£ RDS Database Setup
â¤ Launch RDS MySQL instance in private subnet
â¤ Configure Multi-AZ deployment for high availability
â¤ Set up automated backups
â¤ Create database schemas for each microservice
â¤ Store credentials in AWS Secrets Manager


4ï¸âƒ£ ElastiCache Redis
â¤ Create Redis cluster in private subnet
â¤ Configure cluster mode for scalability
â¤ Set up backup and maintenance windows


Phase 2ï¸âƒ£: EKS Cluster Setup
1ï¸âƒ£ Create EKS Cluster
â¤ Use AWS Console or CLI to create EKS cluster
â¤ Choose Kubernetes version (1.28+)
â¤ Select VPC and subnets created earlier
â¤ Configure cluster endpoint access (public + private)
â¤ Enable control plane logging to CloudWatch


2ï¸âƒ£ Node Groups
â¤ Create managed node group for worker nodes
â¤ Choose instance types (t3.medium/large for production)
â¤ Configure auto-scaling (min: 2, desired: 3, max: 10)
â¤ Enable SSH access for troubleshooting
â¤ Add nodes to private subnets


3ï¸âƒ£ Install Essential Add-ons
â¤ AWS Load Balancer Controller: For ALB integration
â¤ EBS CSI Driver: For persistent volume provisioning
â¤ CoreDNS: For service discovery
â¤ Metrics Server: For resource monitoring
â¤ Cluster Autoscaler: For automatic node scaling


Phase 3ï¸âƒ£: Container Registry Setup
1ï¸âƒ£ Amazon ECR Setup

Create ECR repositories for each microservice:
â¤ user-service
â¤ patient-service
â¤ appointment-service
â¤ billing-service
â¤ pharmacy-service
â¤ laboratory-service
â¤ notification-service
â¤ communication-service
â¤ api-gateway


2ï¸âƒ£ Repository Configuration
â¤ Enable image scanning on push for security
â¤ Set lifecycle policies to remove old images
â¤ Configure cross-region replication for high availability


Phase 4ï¸âƒ£: Jenkins Pipeline Setup
1ï¸âƒ£ Jenkins Installation
â¤ Deploy Jenkins on EC2 instance or EKS cluster
â¤ Install in public subnet with security group allowing port 8080
â¤ Configure persistent storage using EBS volume
â¤ Set up SSL certificate for HTTPS access


2ï¸âƒ£ Jenkins Plugin Installation
â¤ Git plugin for GitHub integration
â¤ Docker Pipleline plugin
â¤ Kubernetes plugin for deployment
â¤ AWS credentials plugin for ECR access
â¤ Pipleline plugin
â¤ GitHub Integration plugin
â¤ Slack/Email notification plugins


3ï¸âƒ£ Jenkins Pipeline Configuration
â¤ Configure AWS credentials for ECR and EKS access.
â¤ Set up kubeconfig for EKS cluster access.
â¤ Create service account in Kubernetes for Jenkins.
â¤ Configure GitHub webhook for automatic triggers
â¤ Set up build agents(master-slave configuration).


Phaes 5ï¸âƒ£: GitHub Repository structure
hospital-management-system/
â”œâ”€â”€ microservices/
â”‚   â”œâ”€â”€ user-service/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ k8s/
â”‚   â”‚       â”œâ”€â”€ deployment.yaml
â”‚   â”‚       â”œâ”€â”€ service.yaml
â”‚   â”‚       â””â”€â”€ configmap.yaml
â”‚   â”œâ”€â”€ patient-service/
â”‚   â”œâ”€â”€ appointment-service/
â”‚   â””â”€â”€ ... (other services)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ k8s/
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ terraform/ (optional)
â”‚   â””â”€â”€ k8s/
â”‚       â”œâ”€â”€ namespace.yaml
â”‚       â”œâ”€â”€ secrets.yaml
â”‚       â””â”€â”€ ingress.yaml
â”œâ”€â”€ jenkins/
â”‚   â””â”€â”€ Jenkinsfile
â””â”€â”€ README.md


Phase 6ï¸âƒ£: Kubernetes Deployment
1ï¸âƒ£ Namespace Setup
â¤ Create separate namespaces for environments (dev, staging, prod)
â¤ Apply resource quotas and limits per namespace


2ï¸âƒ£ ConfigMaps and Secrets
Create ConfigMaps for application properties
Store database URLs, service endpoints
Create Kubernetes Secrets from AWS Secrets Manager
Configure external-secrets operator for automatic sync


3ï¸âƒ£ Deployment Configuration
Each microservice needs:
â¤ Deployment â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Defines pods, replicas, resource limits
â¤ Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Exposes pods internally (ClusterIP)
â¤ HPA â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Horizontal Pod Autoscaler for scaling based on CPU/memory
â¤ PodDisruptionBudget â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Ensures availability during updates


4ï¸âƒ£ Ingress Configuration
â¤ Install NGINX Ingress Controller or use ALB Ingress
â¤ Configure routing rules for each service
â¤ Set up SSL/TLS certificates using AWS ACM
â¤ Configure path-based routing to microservices


Phase 7ï¸âƒ£: Jenkins Pipleline Stages
Pipeline Overview
The Jenkins pipeline will have these stages for each microservice:

Stage 1ï¸âƒ£: Checkout Code
â¤ Pull latest code from GitHub branch
â¤ Triggered by GitHub webhook on push/PR


Stage 2ï¸âƒ£: Build Application
â¤ For Spring Boot: Maven clean package
â¤ For React: npm install and npm build
â¤ Run unit tests and generate reports


Stage 3ï¸âƒ£: Code Quality Analysis
â¤ SonarQube scanning (optional)
â¤ Check test coverage thresholds
â¤ Security vulnerability scanning


Stage 4ï¸âƒ£: Build Docker Image
â¤ Build Docker image using Dockerfile
â¤ Tag image with build number and git commit SHA
â¤ Apply semantic versioning


Stage 5ï¸âƒ£: Push to ECR
â¤ Authenticate with ECR using AWS credentials
â¤ Push Docker image to ECR repository
â¤ Scan image for vulnerabilities



Stage 6ï¸âƒ£: Update Kubernetes Manifests
â¤ Update deployment YAML with new image tag
â¤ Use sed or yq to modify image version
â¤ Commit changes back to Git (GitOps approach)


Stage 7ï¸âƒ£: Deploy to EKS
â¤ Apply updated Kubernetes manifests using kubectl
â¤ Perform rolling update strategy
â¤ Wait for deployment to stabilize


Stage 8ï¸âƒ£: Health Check
â¤ Verify all pods are running
â¤ Check service endpoints are responding
â¤ Run smoke tests against deployed services


Stage 9ï¸âƒ£: Notifications
â¤ Send success/failure notifications via Slack/Email
â¤ Update Jira tickets (if integrated)


Phase 8ï¸âƒ£: Pipeline Workflow
1ï¸âƒ£ Development Flow
â¤ Developer pushes code to feature branch in GitHub
â¤ GitHub webhook triggers Jenkins pipeline
â¤ Jenkins builds and tests the application
â¤ If tests pass, Docker image is built and pushed to ECR
â¤ Image is deployed to DEV namespace in EKS
â¤ Automated tests run against DEV environment


2ï¸âƒ£ Staging Flow
â¤ Developer creates Pull Request to staging branch
â¤ Code review and approval process
â¤ On merge, Jenkins pipeline deploys to STAGING namespace
â¤ QA team performs testing
â¤ Performance and integration tests run


3ï¸âƒ£ Production Flow
â¤ After staging approval, merge to main/production branch
â¤ Jenkins pipeline with additional approval gate
â¤ Deploy to PROD namespace with blue-green or canary strategy
â¤ Monitor CloudWatch metrics and logs
â¤ Rollback capability if issues detected


Phase 9ï¸âƒ£: Monitoring and Logging
1ï¸âƒ£ Logging Setup
â¤ Deploy Fluentd as DaemonSet for log collection
â¤ Forward logs to CloudWatch Logs
â¤ Create log groups for each microservice
â¤ Set up log retention policies


2ï¸âƒ£ Monitoring Setup
â¤ Deploy Prometheus for metrics collection
â¤ Install Grafana for visualization
â¤ Create dashboards for:
    âœ”ï¸ Pod CPU and memory usage
    âœ”ï¸ Request rate and latency
    âœ”ï¸ Database connection pools
    âœ”ï¸ Kafka consumer lag
â¤ Set up alerts for critical thresholds


3ï¸âƒ£ Distributed Tracing
â¤ Implement AWS X-Ray or Jaeger
â¤ Trace requests across microservices
â¤ Identify performance bottlenecks


Phase 1ï¸âƒ£0ï¸âƒ£: Additional Configurations
1ï¸âƒ£ Kafka Setup for Notifications
â¤ Deploy Kafka cluster on EKS using Strimzi operator
â¤ Or use Amazon MSK (Managed Streaming for Kafka)
â¤ Configure topics for appointment reminders, billing alerts
â¤ Set up consumer groups in notification service


2ï¸âƒ£ WebSocket for Real-time Chat
â¤ Deploy communication service with WebSocket support
â¤ Use Redis for session storage across pods
â¤ Configure sticky sessions at load balancer level
â¤ Scale WebSocket pods independently


3ï¸âƒ£ Database Migration Strategy
â¤ Use Liquibase or Flyway for schema migrations
â¤ Run migrations as Kubernetes Jobs before deployment
â¤ Version control all database changes


4ï¸âƒ£ Backup and Disaster Recovery
â¤ Configure RDS automated backups (daily)
â¤ Set up cross-region RDS read replicas
â¤ Backup Kubernetes configurations to S3
â¤ Document restore procedures


ğŸ”„ Security Best Practices
1ï¸âƒ£ Network Security
â¤ Use private subnets for all backend services
â¤ Implement network policies in Kubernetes
â¤ Enable VPC Flow Logs for traffic analysis


2ï¸âƒ£ Application Security
â¤ Store secrets in AWS Secrets Manager, not in code
â¤ Implement JWT token validation in API Gateway
â¤ Enable HTTPS/TLS for all communications
â¤ Regular security patching of base images


3ï¸âƒ£ Access Control
â¤ Use IAM roles for service accounts (IRSA)
â¤ Implement RBAC in Kubernetes
â¤ Enable MFA for AWS console access
â¤ Audit logs for all access attempts


4ï¸âƒ£ Compliance
â¤ Encrypt data at rest (RDS, S3)
â¤ Encrypt data in transit (TLS)
â¤ HIPAA compliance for patient data
â¤ Regular compliance audits


ğŸ”„ Cost Optimization
â¤ Use Spot Instances for non-critical workloads
â¤ Implement cluster autoscaling to scale down during off-hours
â¤ Use Reserved Instances for predictable workloads
â¤ Set up CloudWatch billing alerts
â¤ Right-size EC2 instances based on actual usage
â¤ Use S3 lifecycle policies for old data archival


===========================================================
ğŸ”· Common Deployment Scenarios, Problems, and Solutions
===========================================================
Scenario 1ï¸âƒ£: Database Connection Failures After Deployment
ğŸš« Problem
â¤ Microservices deployed successfully but cannot connect to RDS MySQL database
â¤ Pods are in CrashLoopBackOff state
â¤ Error logs show "Connection refused" or "Unable to connect to database"

ğŸŒŠ Root Causes
â¤ Security group rules not allowing traffic from EKS nodes to RDS
â¤ Wrong database endpoint URL in ConfigMap
â¤ Database credentials not properly synced from AWS Secrets Manager
â¤ RDS instance in different VPC or subnet than expected
â¤ Network ACLs blocking traffic

âœ… Solution
â¤ Verify security group attached to RDS allows inbound traffic on port 3306 from EKS node security group
â¤ Check database endpoint URL is correct (use RDS endpoint, not IP)
â¤ Validate credentials in Kubernetes secrets match RDS master credentials
â¤ Use AWS VPC Reachability Analyzer to test connectivity
â¤ Test connection from within a pod using MySQL client before deploying application
â¤ Ensure proper DNS resolution for RDS endpoint


Scenario 2ï¸âƒ£: Pod Memory/CPU Resource Exhaustion
ğŸš« Problem
â¤ Pods getting OOMKilled (Out of Memory Killed)
â¤ Application becomes unresponsive under load
â¤ Nodes running out of resources
â¤ HPA (Horizontal Pod Autoscaler) not scaling pods

ğŸŒŠ Root Causes
â¤ Resource limits set too low in deployment YAML
â¤ Memory leaks in application code
â¤ No resource requests defined, causing scheduling issues
â¤ JVM heap size not optimized for container environment
â¤ Too many pods scheduled on single node

âœ… Solution
â¤ Set appropriate resource requests and limits based on application profiling
â¤ For Spring Boot: Set JVM heap size to 70-80% of container memory limit
â¤ Monitor actual resource usage in CloudWatch/Prometheus and adjust accordingly
â¤ Configure HPA based on CPU and memory thresholds
â¤ Use VerticalPodAutoscaler for automatic resource adjustment recommendations
â¤ Implement proper connection pooling to prevent resource exhaustion
â¤ Use cluster autoscaler to add nodes when resources are insufficient


Scenario 3: Service Discovery Issues Between Microservices
ğŸš« Problem
â¤ User Service cannot communicate with Patient Service
â¤ DNS resolution failures for service names
â¤ 503 Service Unavailable errors
â¤ Services timing out when calling each other

ğŸŒŠ Root Causes
â¤ Kubernetes Service not created or misconfigured
â¤ Wrong service name used in application properties
â¤ Services deployed in different namespaces without proper DNS addressing
â¤ CoreDNS pods not running properly in kube-system namespace
â¤ Network policies blocking inter-service communication

âœ… Solution
â¤ Verify Kubernetes Services are created with correct selectors matching pod labels
â¤ Use fully qualified domain names: <service-name>.<namespace>.svc.cluster.local
â¤ Check CoreDNS pods are running: kubectl get pods -n kube-system
â¤ Test DNS resolution from within pods using nslookup or dig
â¤ Review and update network policies to allow required traffic
â¤ Use service mesh like Istio for better traffic management and observability
â¤ Ensure service ports match container ports in deployments


Scenario 4ï¸âƒ£: Load Balancer Health Check Failures
ğŸš« Problem
â¤ ALB showing all targets as unhealthy
â¤ Traffic not reaching pods
â¤ 502 Bad Gateway errors from load balancer
â¤ Ingress controller not routing traffic properly

ğŸŒŠ Root Causes
â¤ Health check endpoint not implemented in application
â¤ Health check path misconfigured in ingress/service
â¤ Application takes too long to start (exceeds health check timeout)
â¤ Wrong port configured for health checks
â¤ Security groups blocking health check traffic

âœ… Solution
â¤ Implement /health or /actuator/health endpoint in all microservices
â¤ Configure proper readiness and liveness probes in pod spec
â¤ Increase initialDelaySeconds to allow application startup time
â¤ Set appropriate timeout and failure threshold values
â¤ Ensure health check path returns 200 OK response
â¤ Verify target group settings in ALB match service configurations
â¤ Check security groups allow traffic from ALB to pods on correct ports


Scenario 5ï¸âƒ£: Docker Image Pull Failures
ğŸš« Problem
â¤ Pods stuck in ImagePullBackOff state
â¤ Error: "Failed to pull image" or "ErrImagePull"
â¤ Deployment rollout stuck waiting for pods

ğŸŒŠ Root Causes
â¤ ECR authentication token expired
â¤ Wrong image name or tag in deployment YAML
â¤ IAM role for EKS nodes lacks ECR pull permissions
â¤ Image doesn't exist in ECR repository
â¤ Network issues accessing ECR from private subnets

âœ… Solution
â¤ Verify IAM role attached to EKS node group has â¤ AmazonEC2ContainerRegistryReadOnly policy
â¤ Check image name follows correct format: <account-id>.dkr.ecr.<region>.amazonaws.com/<repo>:<tag>
â¤ List images in ECR to confirm tag exists: aws ecr list-images
â¤ Use imagePullPolicy: Always or IfNotPresent appropriately
â¤ For private repositories, create Kubernetes secret with ECR credentials
â¤ Ensure NAT Gateway is configured for private subnet internet access
â¤ Test image pull manually using docker pull from worker node


Scenario 6ï¸âƒ£: Jenkins Pipeline Authentication Failures
ğŸš« Problem
â¤ Jenkins cannot push images to ECR
â¤ kubectl commands fail with "unauthorized" error
â¤ Jenkins cannot access EKS cluster
â¤ AWS credentials not working in pipeline

ğŸŒŠ Root Causes
â¤ AWS credentials not configured in Jenkins
â¤ IAM role lacks necessary permissions
â¤ Kubeconfig not properly set up for EKS access
â¤ ECR login token expired during long builds
â¤ Service account in Kubernetes not bound to proper role

âœ… Solution
â¤ Configure AWS credentials in Jenkins using AWS Credentials plugin
â¤ Create IAM user/role with ECR push, EKS describe permissions
â¤ Generate and configure kubeconfig for cluster: aws eks update-kubeconfig
â¤ Use aws ecr get-login-password before docker push in pipeline
â¤ Create Kubernetes service account with cluster-admin or specific RBAC permissions
â¤ Store kubeconfig in Jenkins credentials securely
â¤ Use IAM roles for service accounts (IRSA) for better security


Scenario 7ï¸âƒ£: Rolling Update Causing Downtime
ğŸš« Problem
â¤ Application becomes unavailable during deployment
â¤ Users experience connection errors during updates
â¤ Old version pods terminate before new ones are ready
â¤ Database connections lost during rollout

ğŸŒŠ Root Causes
â¤ No readiness probe configured causing traffic to unready pods
â¤ maxUnavailable set too high in deployment strategy
â¤ Application not handling graceful shutdown
â¤ No PodDisruptionBudget configured
â¤ Insufficient replicas to maintain availability

âœ… Solution
â¤ Configure proper readiness probes to ensure pod is ready before receiving traffic
â¤ Set appropriate rolling update strategy: maxSurge: 1, maxUnavailable: 0
â¤ Implement graceful shutdown hook in Spring Boot applications
â¤ Create PodDisruptionBudget to ensure minimum available pods during updates
â¤ Run minimum 2-3 replicas for high availability
â¤ Use preStop lifecycle hooks to drain connections before termination
â¤ Test deployments in staging environment first


Scenario 8ï¸âƒ£: Persistent Volume Claim (PVC) Mounting Issues
ğŸš« Problem
â¤ Pods stuck in ContainerCreating state
â¤ Error: "Unable to mount volumes" or "FailedMount"
â¤ File uploads not persisting after pod restart
â¤ Logs show permission denied errors

ğŸŒŠ Root Causes
â¤ Storage class not available or misconfigured
â¤ EBS CSI driver not installed on cluster
â¤ PVC requesting more storage than available
â¤ Volume in different availability zone than pod
â¤ Incorrect file system permissions

âœ… Solution
â¤ Install AWS EBS CSI driver as cluster add-on
â¤ Create proper storage class with EBS volume type (gp3 recommended)
â¤ Ensure PVC and pod are in same availability zone
â¤ Set appropriate access modes: ReadWriteOnce for EBS
â¤ Configure fsGroup in pod security context for proper permissions
â¤ Use dynamic provisioning instead of static PVs
â¤ For multi-AZ deployments, use EFS instead of EBS with EFS CSI driver


Scenario 9ï¸âƒ£: Environment Variable and Secret Mismatch
ğŸš« Problem
â¤ Application using wrong database in production
â¤ Feature flags not working as expected
â¤ API keys showing as "null" or undefined
â¤ Services connecting to wrong endpoints

ğŸŒŠ Root Causes
â¤ ConfigMaps not updated after deployment
â¤ Wrong namespace selected when creating secrets
â¤ Environment variables not properly referenced in deployment
â¤ Secrets not base64 encoded correctly
â¤ ConfigMap mounted as volume but application reading from env vars

âœ… Solution
â¤ Use consistent naming convention for ConfigMaps across environments
â¤ Verify secrets exist in correct namespace: kubectl get secrets -n <namespace>
â¤ Reference ConfigMaps and Secrets properly in deployment using envFrom or env
â¤ Encode secrets correctly: echo -n 'password' | base64
â¤ Implement external-secrets operator to sync from AWS Secrets Manager automatically
â¤ Use different ConfigMaps for dev, staging, prod environments
â¤ Restart deployments after ConfigMap/Secret updates: kubectl rollout restart


Scenario 1ï¸âƒ£0ï¸âƒ£: Kafka Consumer Lag and Message Loss
ğŸš« Problem
â¤ Notification service not sending alerts
â¤ Messages piling up in Kafka topics
â¤ Duplicate notifications being sent
â¤ Consumer group rebalancing continuously

ğŸŒŠ Root Causes
â¤ Consumer pods crashing before committing offsets
â¤ Not enough consumer instances to handle message load
â¤ Network partition between Kafka and consumers
â¤ Consumer processing time exceeding session timeout
â¤ Auto-commit disabled but manual commit not implemented

âœ… Solution
â¤ Configure proper Kafka consumer properties: session timeout, heartbeat interval
â¤ Scale notification service pods based on partition count
â¤ Implement proper error handling and retry logic
â¤ Use idempotent message processing to handle duplicates
â¤ Monitor consumer lag metrics in Prometheus
â¤ Configure appropriate resource limits for consumer pods
â¤ Use Kafka consumer groups properly with unique group IDs
â¤ Implement dead letter queue for failed messages


Scenario 1ï¸âƒ£1ï¸âƒ£: SSL/TLS Certificate Issues
ğŸš« Problem
â¤ HTTPS not working on application domain
â¤ Browser showing "Not Secure" warning
â¤ Certificate expired errors
â¤ Certificate mismatch with domain name

ğŸŒŠ Root Causes
â¤ Certificate not properly configured in ingress
â¤ AWS ACM certificate not validated
â¤ Wrong certificate ARN used in ALB annotation
â¤ Certificate doesn't cover subdomain or wildcard
â¤ Certificate renewal not automated

âœ… Solution
â¤ Request certificate in AWS ACM for your domain
â¤ Validate certificate using DNS or email validation
â¤ Add certificate ARN annotation to ingress: alb.ingress.kubernetes.io/certificate-arn
â¤ Use wildcard certificates for multiple subdomains
â¤ Configure DNS records to point to ALB endpoint
â¤ Enable automatic certificate renewal in ACM
â¤ Use cert-manager for Let's Encrypt certificates in Kubernetes
â¤ Verify certificate is associated with correct load balancer listener


Scenario 1ï¸âƒ£2ï¸âƒ£: Cross-Origin Resource Sharing (CORS) Errors
ğŸš« Problem
â¤ Frontend cannot communicate with backend APIs
â¤ Browser console showing CORS policy errors
â¤ OPTIONS preflight requests failing
â¤ API calls work in Postman but not in browser

ğŸŒŠ Root Causes
â¤ CORS not configured in Spring Boot backend
â¤ API Gateway not forwarding CORS headers
â¤ Ingress controller stripping CORS headers
â¤ Wrong origin URL configured in CORS policy
â¤ Missing Access-Control headers in response

âœ… Solution
â¤ Configure CORS in Spring Boot using @CrossOrigin or WebMvcConfigurer
â¤ Allow specific origins, not wildcard "*" in production
â¤ Configure CORS in API Gateway or ingress annotations
â¤ Ensure OPTIONS method is allowed for preflight requests
â¤ Add proper CORS headers: Access-Control-Allow-Origin, Methods, Headers
â¤ Test CORS configuration using curl with Origin header
â¤ Use NGINX ingress CORS annotations if using NGINX controller


Scenario 1ï¸âƒ£3ï¸âƒ£: WebSocket Connection Failures
ğŸš« Problem
â¤ Real-time chat not working
â¤ WebSocket connections dropping frequently
â¤ Sticky session not working, users connecting to different pods
â¤ 101 Switching Protocols response not received

ğŸŒŠ Root Causes
â¤ Load balancer not configured for WebSocket support
â¤ Ingress timeout too short for long-lived connections
â¤ No sticky sessions causing connection to different pod on reconnect
â¤ WebSocket path not properly configured in ingress
â¤ Security groups blocking WebSocket traffic

âœ… Solution
â¤ Configure ALB target group with sticky sessions (session affinity)
â¤ Increase ingress timeout annotations for WebSocket paths
â¤ Use NGINX ingress with proper WebSocket annotations
â¤ Configure Spring Boot WebSocket endpoint properly
â¤ Use Redis for session storage across pods
â¤ Enable WebSocket support in API Gateway if using it
â¤ Test WebSocket endpoint using wscat tool
â¤ Monitor connection metrics and implement reconnection logic in frontend


Scenario 1ï¸âƒ£4ï¸âƒ£: Database Migration Failures
ğŸš« Problem
â¤ Schema changes not applied before new code deployment
â¤ Application crashes due to missing database columns
â¤ Migration scripts failing midway
â¤ Database locked during migration

ğŸŒŠ Root Causes
â¤ Migrations running as application startup instead of separate job
â¤ Multiple pods running migrations simultaneously
â¤ Migration scripts not idempotent
â¤ Database user lacks necessary permissions
â¤ Incompatible schema changes with zero-downtime deployment

âœ… Solution
â¤ Run Liquibase/Flyway migrations as Kubernetes Job before deployment
â¤ Use init containers for migrations with proper locking
â¤ Ensure migration scripts are idempotent (can run multiple times safely)
â¤ Grant proper database privileges to migration user
â¤ Use backward-compatible schema changes (add columns as nullable first)
â¤ Version control all migration scripts
â¤ Test migrations in staging environment first
â¤ Implement blue-green deployments for breaking schema changes
â¤ Use database transaction rollback for failed migrations


Scenario 1ï¸âƒ£5ï¸âƒ£: Auto-Scaling Not Working Properly
ğŸš« Problem
â¤ HPA not scaling pods despite high CPU/memory usage
â¤ Cluster autoscaler not adding nodes
â¤ Pods pending due to insufficient resources
â¤ Scaling happening too slowly during traffic spikes

ğŸŒŠ Root Causes
â¤ Metrics server not installed or not functioning
â¤ Resource requests not defined in pod spec (HPA requirement)
â¤ Scaling thresholds set incorrectly
â¤ Cluster autoscaler not configured with proper IAM permissions
â¤ Node group max size reached
â¤ PodDisruptionBudget preventing scale down

âœ… Solution
â¤ Install metrics-server: kubectl apply -f metrics-server.yaml
â¤ Define resource requests in all deployments (required for HPA)
â¤ Configure HPA with appropriate CPU/memory thresholds (e.g., 70%)
â¤ Attach IAM policy for autoscaling to cluster autoscaler
â¤ Increase maximum node count in node group configuration
â¤ Use custom metrics from CloudWatch or Prometheus for better scaling decisions
â¤ Configure scale-down delay and stabilization windows appropriately
â¤ Test scaling behavior with load testing tools like JMeter


Scenario 1ï¸âƒ£6ï¸âƒ£: Jenkins Build Timeouts
ğŸš« Problem
â¤ Jenkins pipeline failing with timeout errors
â¤ Maven/npm builds taking extremely long time
â¤ Docker build step hanging indefinitely
â¤ Pipeline stuck at deployment stage

ğŸŒŠ Root Causes
â¤ No timeout configured, causing indefinite waits
â¤ Network issues downloading dependencies
â¤ Insufficient resources on Jenkins agents
â¤ Large Docker image layers not cached
â¤ Deployment waiting for pod readiness indefinitely

âœ… Solution
â¤ Set appropriate timeout values in Jenkinsfile for each stage
â¤ Configure Maven/npm to use corporate repository mirrors or Artifactory
â¤ Increase Jenkins agent memory and CPU allocation
â¤ Use multi-stage Docker builds and layer caching
â¤ Implement healthcheck timeout in deployment wait steps
â¤ Use Jenkins declarative pipeline timeout directive
â¤ Configure retry logic for flaky network operations
â¤ Monitor Jenkins agent resource usage and scale appropriately


Scenario 1ï¸âƒ£7ï¸âƒ£: Logging and Monitoring Gaps
ğŸš« Problem
â¤ Cannot find application logs when debugging issues
â¤ No visibility into microservice performance
â¤ Unable to trace requests across services
â¤ Alerts not firing when issues occur

ğŸŒŠ Root Causes
â¤ Logs not being forwarded to CloudWatch
â¤ Fluentd/Fluent Bit not deployed or misconfigured
â¤ Application logging to wrong output (not stdout/stderr)
â¤ Prometheus not scraping application metrics
â¤ No alerting rules configured

âœ… Solution
â¤ Deploy Fluentd or Fluent Bit as DaemonSet on all nodes
â¤ Configure application to log to stdout/stderr (Docker/Kubernetes standard)
â¤ Use structured logging (JSON format) for better parsing
â¤ Expose /metrics endpoint in all services for Prometheus scraping
â¤ Add Prometheus annotations to pods for automatic discovery
â¤ Implement distributed tracing using AWS X-Ray or Jaeger
â¤ Create CloudWatch log groups for each microservice
â¤ Configure Prometheus alerting rules and Alertmanager
â¤ Set up Grafana dashboards for visualization
â¤ Implement centralized logging with proper log retention policies


Scenario 1ï¸âƒ£8ï¸âƒ£: Git Conflicts in Deployment Manifests
ğŸš« Problem
â¤ Multiple developers pushing changes causing merge conflicts
â¤ Production deployment using wrong image tag
â¤ Rolling back deployment accidentally deploys old version
â¤ ConfigMaps overwritten by automated pipeline

ğŸŒŠ Root Causes
â¤ Manual edits to deployment files in cluster vs Git
â¤ No GitOps workflow implemented
â¤ Image tags not properly managed
â¤ Multiple pipelines modifying same files simultaneously

âœ… Solution
â¤ Implement GitOps using ArgoCD or FluxCD
â¤ Use Git as single source of truth for all Kubernetes manifests
â¤ Never manually edit resources in cluster (use kubectl apply from Git)
â¤ Use semantic versioning for Docker image tags
â¤ Create separate Git branches for each environment
â¤ Implement pull request workflow with approvals
â¤ Use Kustomize or Helm for environment-specific configurations
â¤ Tag Git commits corresponding to production deployments
â¤ Implement automated rollback based on Git history


Scenario 1ï¸âƒ£9ï¸âƒ£: Network Policy Blocking Legitimate Traffic
ğŸš« Problem
â¤ Services cannot communicate despite being in same cluster
â¤ Database connections randomly failing
â¤ External API calls not working from pods
â¤ DNS âœ… resolution failing intermittently

ğŸŒŠ Root Causes
â¤ Restrictive network policies applied without proper testing
â¤ Network policies blocking kube-dns/CoreDNS traffic
â¤ Egress policies preventing external API access
â¤ Policy selectors not matching intended pods

âœ… Solution
â¤ Start with permissive policies and gradually restrict
â¤ Always allow DNS traffic to kube-system namespace in policies
â¤ Create separate network policies for ingress and egress
â¤ Use proper label selectors in policies matching pod labels
â¤ Test network connectivity after applying policies
â¤ Document network policy requirements for each microservice
â¤ Use network policy visualizers to understand impact
â¤ Implement default deny policies with explicit allow rules
â¤ Test using kubectl exec to verify connectivity between pods


Scenario 2ï¸âƒ£0ï¸âƒ£: Disaster Recovery and Backup Failures
ğŸš« Problem
â¤ Database backup not running as scheduled
â¤ Cannot restore from backup when needed
â¤ Kubernetes state not backed up
â¤ Configuration lost after cluster recreation

ğŸŒŠ Root Causes
â¤ RDS automated backups disabled or misconfigured
â¤ No backup âœ… solution for Kubernetes resources
â¤ Backup retention period too short
â¤ Restore procedures not tested or documented
â¤ Backup stored in same region as primary

âœ… Solution
â¤ Enable RDS automated backups with appropriate retention (7-30 days)
â¤ Configure manual snapshots before major changes
â¤ Use Velero for Kubernetes cluster backup and restore
â¤ Backup etcd snapshots regularly (EKS handles this automatically)
â¤ Store backups in different region for disaster recovery
â¤ Version control all Kubernetes manifests in Git
â¤ Export and backup ConfigMaps, Secrets regularly
â¤ Document and test restore procedures quarterly
â¤ Implement point-in-time recovery for RDS
â¤ Use AWS Backup for centralized backup management
â¤ Create runbooks for different disaster scenarios


======================================
ğŸ”· Microservices Detailed Analysis
======================================
ğŸ”„ Services with their port numbers:
â¤ Eureka Server (8761) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Service Discovery
â¤ UserMS (8080) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Authentication
â¤ ProfileMS (9100) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Doctor & Patient Profiles
â¤ AppointmentMS (9200) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Appointments, Medical Records, Prescriptions
â¤ PharmacyMS (9300) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Medicine Inventory & Sales
â¤ MediaMS (9400) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ File Storage
â¤ Gateway â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ JWT Validation & Routing


ğŸ”„ Technology Stack
Every technology used in your project:
â¤ Spring Boot 3.5.6/3.5.7
â¤ Spring Cloud 2025.0.0
â¤ Java 8
â¤ MySQL 8
â¤ JWT, BCrypt, OpenFeign, Eureka
â¤ React, Tailwind CSS (frontend)


ğŸ”„ Complete Application Flows
â¤ Patient Registration â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ User creation â†’ Profile creation â†’ Database entries
â¤ Doctor Registration â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Similar with doctor â”€ specific fields
â¤ User Login â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ JWT generation with all claims
â¤ Appointment Booking â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Verification â†’ Scheduling â†’ Database updates
â¤ Doctor Consultation â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Medical record creation â†’ Status updates
â¤ Prescription Creation â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Prescription â†’ Medicine linking â†’ PharmacyMS reference
â¤ Pharmacy Medicine Management â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Master catalog â†’ Inventory batches
â¤ Pharmacy Sale Processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Prescription linking â†’ Stock reduction â†’ Sale items
â¤ Medical Document Upload â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ File storage as BLOB â†’ Retrieval






































Database Design: Relationships (one-to-many: Doctor to Appointments), normalization, indexes on frequent queries like patient history.
Spring Boot Implementation: Security with JWT/Spring Security for RBAC, REST controllers with @PreAuthorize, scheduling via @Scheduled or Quartz.
Challenges & âœ… Solutions: Discuss concurrency in bookings (optimistic locking with @Version), file uploads for reports (Spring MultipartFile to S3/minio), payment integration (Stripe/Razorpay webhooks).
Code Walkthrough: Prepare to share GitHub repo; explain a complex service like BillingService with transaction management (@Transactional).
Scalability: Microservices potential (separate Appointment and Patient services), caching (Redis for doctor availability), Docker deployment.


Feature Revision Order (Day-by-Day)
Today (High-impact core - 4-5 hours):

ğŸ‘‰ User Management + RBAC (30min): Login flows, @PreAuthorize, roles cascade to features

ğŸ‘‰ Patient Management (45min): Registration â†’ Medical Records â†’ File uploads

ğŸ‘‰ Appointment Scheduling (60min): Calendar API, slot conflicts, doctor availabilityâ€”most likely grilled

ğŸ‘‰ Billing (45min): Invoice generation, payment webhooks, @Transactional dues calculation

Tomorrow Morning (Money + Metrics - 3 hours):
5. Reporting Dashboard (45min): Key metrics, filters, Chart.js queries
6. Pharmacy + Lab (45min): Inventory triggers, prescription linking

Tomorrow Afternoon (Polish - 2 hours):
7. Notifications (30min): Email/SMS service, WebSocket chat
8. Cross-cutting (60min): Error handling, validation, security across features

Microservices Layer (30min Total)
Only after features. Prepare one slide/diagram showing: